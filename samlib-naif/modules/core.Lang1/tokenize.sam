## Copyright 2013-2014 the Samizdat Authors (Dan Bornstein et alia).
## Licensed AS IS and WITHOUT WARRANTY under the Apache License,
## Version 2.0. Details: <http://www.apache.org/licenses/LICENSE-2.0>

##
## Samizdat Layer 1 tokenizer
##
## The following is a near-transliteration of the token grammar in
## the Samizdat Layer 0 and Samizdat Layer 1 specifications.
##

#= language core.Lang0

import core.Generator;
import core.LangNode :: KEYWORDS, intFromDigits;
import core.Peg :: *;


##
## These definitions are meant to mirror the code in the spec for
## tokenization, as closely as possible.
##

## Documented in spec.
def tokWhitespace = makeMainSequence(
    makeLookaheadSuccess(makeCharSet("# \n")),
    makeRepeat(
        makeChoice(
            makeRepeat(makeCharSet(" \n"), 1),
            makeSequence(
                makeString("#"),
                makeCharSet("#!="),
                makeRepeat(makeCharSetComplement("\n")))),
        1));

## Documented in spec.
def tokPunctuation = makeMainSequence(
    makeLookaheadSuccess(
        makeCharSet("@:.,=-+?;*/<>{}()[]", "&|!%")),
    makeChoice(
        makeString("->"),
        makeString(":="),
        makeString("::"),
        makeString(".."),
        makeString("@@"),
        makeString("{:"),
        makeString(":}"),
        any));

## Documented in spec.
def tokDecDigit = makeMainSequence(
    makeCharSet("_0123456789"));

## Documented in spec.
def tokInt = makeMainSequence(
    makeRepeat(tokDecDigit, 1),
    makeCode { digits -> @int{value: intFromDigits(10, digits)} });

## Documented in spec.
def tokStringPart = makeMainChoice(
    makeSequence(
        makeRepeat(makeCharSetComplement("\\\"\n"), 1),
        makeCode(stringFromTokenList)),
    makeSequence(
        makeString("\n"),
        makeRepeat(makeString(" ")),
        makeResult("\n")),
    makeSequence(
        makeString("\\"),
        makeChoice(
            makeSequence(makeString("\\"), makeResult("\\")),
            makeSequence(makeString("\""), makeResult("\"")),
            makeSequence(makeString("n"),  makeResult("\n")),
            makeSequence(makeString("r"),  makeResult("\r")),
            makeSequence(makeString("t"),  makeResult("\t")),
            makeSequence(makeString("0"),  makeResult("\0")))));

## Documented in spec.
def tokString = makeMainSequence(
    makeString("\""),
    makeRepeat(tokStringPart),
    makeChoice(
        makeSequence(
            makeString("\""),
            makeCode { ., parts, . -> @string{value: "".cat(parts*)} }),
        makeCode { ., . -> @error{value: "Unterminated string literal."} }));

## These are all the characters which are allowed to start an identifier.
def IDENTIFIER_START_CHARS =
    "_$abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ";

## These are all the characters which are allowed to be in an identifier.
def IDENTIFIER_CHARS = IDENTIFIER_START_CHARS.cat("0123456789");

## Documented in spec.
def tokIdentifier = makeMainSequence(
    makeCharSet(IDENTIFIER_START_CHARS),
    makeRepeat(makeCharSet(IDENTIFIER_CHARS)),
    makeCode { one, rest ->
        def string = stringFromTokenList([one, rest*]);
        ifValueOr { KEYWORDS.get(string) }
            { @identifier{value: string} }
    });

## Documented in spec.
def tokQuotedIdentifier = makeMainSequence(
    makeString("\\"),
    tokString,
    makeCode { ., s -> @identifier{value: s::value} });

## Documented in spec.
def tokError = makeMainSequence(
    any,
    makeRepeat(makeCharSetComplement("\n")),
    makeCode { badCh, . ->
        def msg = "Unrecognized character: ".cat(get_classNameString(badCh));
        @error{value: msg}
    });

## Documented in spec.
def tokToken = makeMainChoice(
    tokString,
    tokIdentifier,
    tokQuotedIdentifier,
    tokPunctuation,
    tokInt,
    tokError);

## Documented in spec.
def tokFile = makeMainSequence(
    makeRepeat(
        makeSequence(
            makeRepeat(tokWhitespace, 0, 1),
            tokToken)),
    makeRepeat(tokWhitespace, 0, 1),
    makeCode { tokens, . -> tokens });


##
## Exported Definitions
##

## Documented in spec.
export fn tokenize(programText) {
    return apply(tokFile, programText)
};

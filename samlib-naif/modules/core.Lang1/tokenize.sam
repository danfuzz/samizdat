## Copyright 2013-2014 the Samizdat Authors (Dan Bornstein et alia).
## Licensed AS IS and WITHOUT WARRANTY under the Apache License,
## Version 2.0. Details: <http://www.apache.org/licenses/LICENSE-2.0>

##
## Samizdat Layer 1 tokenizer
##
## The following is a near-transliteration of the token grammar in
## the Samizdat Layer 0 and Samizdat Layer 1 specifications.
##

#= language core.Lang0

import core.Generator;
import core.LangNode :: intFromDigits;
import core.Peg :: *;


##
## These definitions are meant to mirror the code in the spec for
## tokenization, as closely as possible.
##

## Map of all the keywords, from their string name to valueless tokens. These
## are (to a first approximation) operators whose spellings match the
## tokenization syntax of identifiers.
def KEYWORDS = $Generator::collectAsMap(
    $Generator::makeFilterGenerator([
        "break", "continue", "def", "export", "fn", "import", "return",
        "var", "yield",
        ## Layer 2 defines additional keywords here.
        []*])
        { name -> {(name): @(@@(name))} });

## Documented in spec.
def tokWhitespace = makeMainSequence(
    makeLookaheadSuccess(makeCharSet("# \n")),
    makeRepeat(
        makeChoice(
            makeRepeat(makeCharSet(" \n"), 1),
            makeSequence(
                makeString("#"),
                makeCharSet("#!="),
                makeRepeat(makeCharSetComplement("\n")))),
        1));

## Documented in spec.
def tokPunctuation = makeMainSequence(
    makeLookaheadSuccess(
        makeCharSet("@:.,=-+?;*/<>{}()[]", "&|!%")),
    makeChoice(
        makeString("->"),
        makeString(":="),
        makeString("::"),
        makeString(".."),
        makeString("@@"),
        makeString("{:"),
        makeString(":}"),
        any));

## Documented in spec.
def tokDecDigit = makeMainSequence(
    makeCharSet("_0123456789"));

## Documented in spec.
def tokInt = makeMainSequence(
    makeRepeat(tokDecDigit, 1),
    makeCode { digits -> @int(intFromDigits(10, digits)) });

## Documented in spec.
def tokStringPart = makeMainChoice(
    makeSequence(
        makeRepeat(makeCharSetComplement("\\\"\n"), 1),
        makeCode(stringFromTokenList)),
    makeSequence(
        makeString("\n"),
        makeRepeat(makeString(" ")),
        makeResult("\n")),
    makeSequence(
        makeString("\\"),
        makeChoice(
            makeSequence(makeString("\\"), makeResult("\\")),
            makeSequence(makeString("\""), makeResult("\"")),
            makeSequence(makeString("n"),  makeResult("\n")),
            makeSequence(makeString("r"),  makeResult("\r")),
            makeSequence(makeString("t"),  makeResult("\t")),
            makeSequence(makeString("0"),  makeResult("\0")))));

## Documented in spec.
def tokString = makeMainSequence(
    makeString("\""),
    makeRepeat(tokStringPart),
    makeChoice(
        makeSequence(
            makeString("\""),
            makeCode { ., parts, . -> @string(cat("", parts*)) }),
        makeCode { ., . -> @error("Unterminated string literal.") }));

## These are all the characters which are allowed to start an identifier.
def IDENTIFIER_START_CHARS =
    "_$abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ";

## These are all the characters which are allowed to be in an identifier.
def IDENTIFIER_CHARS = cat(IDENTIFIER_START_CHARS, "0123456789");

## Documented in spec.
def tokIdentifier = makeMainSequence(
    makeCharSet(IDENTIFIER_START_CHARS),
    makeRepeat(makeCharSet(IDENTIFIER_CHARS)),
    makeCode { one, rest ->
        def string = stringFromTokenList([one, rest*]);
        ifValueOr { get(KEYWORDS, string) }
            { @identifier(string) }
    });

## Documented in spec.
def tokQuotedIdentifier = makeMainSequence(
    makeString("\\"),
    tokString,
    makeCode { ., s -> @identifier(dataOf(s)) });

## Documented in spec.
def tokError = makeMainSequence(
    any,
    makeRepeat(makeCharSetComplement("\n")),
    makeCode { badCh, . ->
        def msg = cat("Unrecognized character: ", get_typeName(badCh));
        @error(msg)
    });

## Documented in spec.
def tokToken = makeMainChoice(
    tokString,
    tokIdentifier,
    tokQuotedIdentifier,
    tokPunctuation,
    tokInt,
    tokError);

## Documented in spec.
def tokFile = makeMainSequence(
    makeRepeat(
        makeSequence(
            makeRepeat(tokWhitespace, 0, 1),
            tokToken)),
    makeRepeat(tokWhitespace, 0, 1),
    makeCode { tokens, . -> tokens });


##
## Exported Definitions
##

## Documented in spec.
export fn tokenize(programText) {
    return apply(tokFile, programText)
};

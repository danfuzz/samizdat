# Copyright 2013 the Samizdat Authors (Dan Bornstein et alia).
# Licensed AS IS and WITHOUT WARRANTY under the Apache License,
# Version 2.0. Details: <http://www.apache.org/licenses/LICENSE-2.0>

#
# Samizdat Layer 2 Tokenizer
#

#
# Helper definitions
#

# These are all the int digits, as a map from strings to digit values. This
# includes hex digits as well, in both lower and upper case. Finally, this
# includes a mapping of `"_"` to `-1` for the implementation of the
# "digit space" syntax.
INT_CHARS = [
    "0"=0, "1"=1, "2"=2, "3"=3, "4"=4, "5"=5, "6"=6, "7"=7, "8"=8, "9"=9,
    "a"=10, "b"=11, "c"=12, "d"=13, "e"=14, "f"=15,
    "A"=10, "B"=11, "C"=12, "D"=13, "E"=14, "F"=15,
    "_"=-1
];

# Helper to convert digit characters to digit values.
intFromDigitChar = { ch :: <> mapGet(INT_CHARS, tokenType(ch)) };

# Map of all the keywords, from their string name to valueless tokens. These
# are (to a first approximation) operators whose spellings match the
# tokenization syntax of identifiers.
KEYWORDS = listReduce([=],
    ["else", "if"])
    { result . name :: <> mapPut(result, name, @[name]) };


#
# Grammar rules
#

# Parses a `/* ... */` comment, with nesting.
tokMultilineComment = forwardFunction();
implMultilineComment = {/
    "/*"

    (
        tokMultilineComment
    |
        [! "*"]
    |
        "*" [! "/"]
    )*

    "*/"
/};
tokMultilineComment(implMultilineComment);

# Parses whitespace and comments. **Note:** The yielded result is always
# ignored.
tokWhitespace = {/
    [" " "\n"]
|
    "#" [! "\n"]* "\n"
|
    tokMultilineComment
/};

# Parses punctuation and operators. The lookahead is done to avoid bothering
# with the choice expression unless we have a definite match.
tokPunctuation = {/
    &["\\-/%&|^!@:,.=+?;*<>{}()[]"]
    (
        "\\==" | "\\!=" | "\\<=" | "\\>=" | "\\<" | "\\>"
    |
        "&&&" | "|||" | "^^^" | "!!!" | "<<<" | ">>>"
    |
        "@@" | "::" | "<>" | "()" | "&&" | "||" | ".." | "{/" | "/}" |
        "==" | "!=" | "<=" | ">="
    |
        # Note: We check this error condition here instead of in the
        # comment parsing code, because comments get parsed as whitespace,
        # which gets ignored. Rather than changing to not-quite-ignore
        # whitespace -- which would be messy -- we instead notice `/*` here
        # where we're parsing other punctuation. This is clean but a little
        # non-obvious, hence this comment.
        "/*" .*
        { <> @["error" = "Unterminated comment."] }
    |
        # Single-character punctuation / operator.
        .
    )
/};

# Parses a single character, inside a quoted string.
tokStringChar = {/
    (
        ch = [! "\\" "\""]
        { <> tokenType(ch) }
    )
|
    (
        "\\"
        (
            "\\" { <> "\\" } |
            "\"" { <> "\"" } |
            "n"  { <> "\n" } |
            "0"  { <> "\0" }
        )
    )
/};

# Parses a quoted string.
tokString = {/
    "\""
    chars = tokStringChar*

    (
        "\""
        { <> @["string" = apply(stringAdd, chars)] }
    |
        { <> @["error" = "Unterminated string literal."] }
    )
/};

# Parses an identifier (in the usual form). This also parses keywords.
tokIdentifier = {/
    first = ["_" "a".."z" "A".."Z"]
    rest = ["_" "a".."z" "A".."Z" "0".."9"]*
    {
        string = stringFromTokenList(listPrepend(first, rest));
        <> ifValue { <> mapGet(KEYWORDS, string) }
            { keyword :: <> keyword }
            { <> @["identifier" = string] }
    }
/};

# Parses the quoted-string identifier form.
tokQuotedIdentifier = {/
    "\\"
    s = tokString
    { <> @["identifier" = tokenValue(s)] }
/};

# Parses an integer literal.
tokInt = {/
    base = (
        "0x" { <> 16 }
    |
        "0b" { <> 2 }
    |
        { <> 10 }
    )

    digits = (
        &&(eq(base, 10))
        (ch=["_" "0".."9"] { <> intFromDigitChar(ch) })+
    |
        &&(eq(base, 16))
        (ch=["_" "0".."9" "a".."f" "A".."F"] { <> intFromDigitChar(ch) })+
    |
        &&(eq(base, 2))
        (ch=["_01"] { <> intFromDigitChar(ch) })+
    )

    {
        value = listReduce(0, digits) { result . digit ::
            <> ifTrue { <> eq(digit, -1) }
                { <> result }
                { <> iadd(imul(result, base), digit) }
        };
        <> @["int" = value]
    }
/};

# "Parses" an unrecognized character. This also consumes any further characters
# on the same line, in an attempt to resynch the input.
tokError = {/
    badCh = .
    [! "\n"]*
    {
        msg = format("Unrecognized character: %q", tokenType(badCh));
        <> @["error" = msg]
    }
/};

# Parses an arbitrary token or error.
tokToken = {/
    tokString | tokIdentifier | tokQuotedIdentifier
|
    # This needs to be listed after the quoted identifier rule, to
    # prevent `\"...` from being treated as a `\` token followed by
    # a string.
    tokPunctuation
|
    # This needs to be listed after the identifier rule, to prevent
    # an identifier-initial `_` from triggering this rule.
    tokInt
|
    tokError
/};

# Parses a file of tokens, yielding a list of them.
tokFile = {/
    tokens=(tokWhitespace* tokToken)* tokWhitespace*
    { <> tokens }
/};


#
# Exported functions
#

# Documented in Samizdat Layer 1 spec.
sam2Tokenize = { programText ::
    <> pegApply(tokFile, programText)
};

<> [
    "sam2Tokenize" = sam2Tokenize
]

# Copyright 2013 the Samizdat Authors (Dan Bornstein et alia).
# Licensed AS IS and WITHOUT WARRANTY under the Apache License,
# Version 2.0. Details: <http://www.apache.org/licenses/LICENSE-2.0>

#
# Samizdat Layer 2 Tokenizer
#

#
# Helper definitions
#

# These are all the int digits, as a map from strings to digit values. This
# includes hex digits as well, in both lower and upper case. Finally, this
# includes a mapping of `"_"` to `-1` for the implementation of the
# "digit space" syntax.
INT_CHARS = [
    "0"=0, "1"=1, "2"=2, "3"=3, "4"=4, "5"=5, "6"=6, "7"=7, "8"=8, "9"=9,
    "a"=10, "b"=11, "c"=12, "d"=13, "e"=14, "f"=15,
    "A"=10, "B"=11, "C"=12, "D"=13, "E"=14, "F"=15,
    "_"=-1
];

# Helper to convert digit characters to digit values.
intFromDigitChar = { ch :: <> mapGet(INT_CHARS, tokenType(ch)) };

# Map of all the "named" operators (whose character set includes some symbol
# characters too, to allow for the value-general ordering operators), from
# strings of the unadorned name to valueless tokens whose type is the adorned
# name.
NAMED_OPERATORS = listReduce([=],
    [
        "==", "!=", "<", ">", "<=", ">=",
        "and", "eqv", "nand", "nor", "not", "or", "shl", "shr", "xor"
    ])
    { result . name :: <> mapPut(result, name, @[stringAdd(".", name, ".")]) };


#
# Grammar rules
#

# Parses a `/* ... */` comment, with nesting.
tokMultilineComment = forwardFunction();
implMultilineComment = {/
    "/*"

    (
        tokMultilineComment
    |
        [! "*"]
    |
        "*" [! "/"]
    )*

    "*/"
/};
tokMultilineComment(implMultilineComment);

# Parses whitespace and comments. **Note:** The yielded result is always
# ignored.
tokWhitespace = {/
    [" " "\n"]
|
    "#" [! "\n"]* "\n"
|
    tokMultilineComment
/};

# Parses punctuation and operators. The lookahead is done to avoid bothering
# with the choice expression unless we have a definite match.
tokPunctuation = {/
    &["-/%&|!@:,.=+?;*<>{}()[]"]
    (
        # These are all the "named" operators.
        "."
        name = ["a".."z" "A".."Z" "!=<>"]+
        "."
        {
            nameString = stringFromTokenList(name);
            <> ifValue { <> mapGet(NAMED_OPERATORS, nameString) }
                { token :: <> token }
                {
                    message =
                        format("Unrecognized named operator: %q", nameString);
                    <> @["error" = message]
                }
        }
    |
        "@@" | "::" | "<>" | "()" | "&&" | ".." | "{/" | "/}"
    |
        # Note: We check this error condition here instead of in the
        # comment parsing code, because comments get parsed as whitespace,
        # which gets ignored. Rather than changing to not-quite-ignore
        # whitespace -- which would be messy -- we instead notice `/*` here
        # where we're parsing other punctuation. This is clean but a little
        # non-obvious, hence this comment.
        "/*" .*
        { <> @["error" = "Unterminated comment."] }
    |
        .
    )
/};

# Parses a single character, inside a quoted string.
tokStringChar = {/
    (
        ch = [! "\\" "\""]
        { <> tokenType(ch) }
    )
|
    (
        "\\"
        (
            "\\" { <> "\\" } |
            "\"" { <> "\"" } |
            "n"  { <> "\n" } |
            "0"  { <> "\0" }
        )
    )
/};

# Parses a quoted string.
tokString = {/
    "\""
    chars = tokStringChar*

    (
        "\""
        { <> @["string" = apply(stringAdd, chars)] }
    |
        { <> @["error" = "Unterminated string literal."] }
    )
/};

# Parses an identifier (in the usual form).
tokIdentifier = {/
    first = ["_" "a".."z" "A".."Z"]
    rest = ["_" "a".."z" "A".."Z" "0".."9"]*
    { <> @["identifier" = stringFromTokenList(listPrepend(first, rest))] }
/};

# Parses the quoted-string identifier form.
tokQuotedIdentifier = {/
    "\\"
    s = tokString
    { <> @["identifier" = tokenValue(s)] }
/};

# Parses an integer literal.
tokInt = {/
    base = (
        "0x" { <> 16 }
    |
        "0b" { <> 2 }
    |
        { <> 10 }
    )

    digits = (
        &&(eq(base, 10))
        (ch=["_" "0".."9"] { <> intFromDigitChar(ch) })+
    |
        &&(eq(base, 16))
        (ch=["_" "0".."9" "a".."f" "A".."F"] { <> intFromDigitChar(ch) })+
    |
        &&(eq(base, 2))
        (ch=["_01"] { <> intFromDigitChar(ch) })+
    )

    {
        value = listReduce(0, digits) { result . digit ::
            <> ifTrue { <> eq(digit, -1) }
                { <> result }
                { <> iadd(imul(result, base), digit) }
        };
        <> @["int" = value]
    }
/};

# "Parses" an unrecognized character. This also consumes any further characters
# on the same line, in an attempt to resynch the input.
tokError = {/
    badCh = .
    [! "\n"]*
    {
        msg = format("Unrecognized character: %q", tokenType(badCh));
        <> @["error" = msg]
    }
/};

# Parses an arbitrary token or error.
tokToken = {/
    tokPunctuation | tokString | tokIdentifier | tokQuotedIdentifier
|
    # This needs to be listed *after* the identifier rule, to prevent
    # an identifier-initial `_` from triggering this rule.
    tokInt
|
    tokError
/};

# Parses a file of tokens, yielding a list of them.
tokFile = {/
    tokens=(tokWhitespace* tokToken)* tokWhitespace*
    { <> tokens }
/};


#
# Exported functions
#

# Documented in Samizdat Layer 1 spec.
sam2Tokenize = { programText ::
    <> pegApply(tokFile, programText)
};

<> [
    "sam2Tokenize" = sam2Tokenize
]

# Copyright 2013 the Samizdat Authors (Dan Bornstein et alia).
# Licensed AS IS and WITHOUT WARRANTY under the Apache License,
# Version 2.0. Details: <http://www.apache.org/licenses/LICENSE-2.0>

#
# Samizdat Layer 2 Tokenizer
#

#
# Helper definitions
#

# These are all the int digits, as a map from strings to digit values. This
# includes hex digits as well, in both lower and upper case. Finally, this
# includes a mapping of `"_"` to `-1` for the implementation of the
# "digit space" syntax.
def INT_CHARS = [
    "0": 0, "1": 1, "2": 2, "3": 3, "4": 4,
    "5": 5, "6": 6, "7": 7, "8": 8, "9": 9,
    "a": 10, "b": 11, "c": 12, "d": 13, "e": 14, "f": 15,
    "A": 10, "B": 11, "C": 12, "D": 13, "E": 14, "F": 15,
    "_": -1
];

# Helper to convert digit characters to digit values.
fn intFromDigitChar(ch) { <> mapGet(INT_CHARS, tokenType(ch)) };

# Map of all the keywords, from their string name to valueless tokens. These
# are (to a first approximation) operators whose spellings match the
# tokenization syntax of identifiers.
def KEYWORDS = listReduce([:],
    [
        "break", "collect", "continue", "def", "default", "do", "else",
        "export", "fn", "for", "if", "import", "in", "module", "reduce",
        "return", "switch", "var", "while"
    ])
    { result, ., name :: <> [result*, (name): @[(name)]] };

# Converts a list of digit values into an int, given the base. If `baseSign`
# is negative, this indicates that the result should be negative.
fn intFromDigitList(baseSign, digits) {
    def base = iabs(baseSign);
    def value = listReduce(0, digits) { result, ., digit ::
        <> ifIs { <> eq(digit, -1) }
            { <> result }
            { <> iadd(imul(result, base), digit) }
    };

    <> imul(value, isign(baseSign))
};


#
# Grammar rules
#

# Parses a `/* ... */` comment, with nesting.
def tokMultilineComment = forwardFunction();
def implMultilineComment = {/
    "/*"

    (
        tokMultilineComment
    |
        [! "*"]
    |
        "*" [! "/"]
    )*

    "*/"
/};
tokMultilineComment(implMultilineComment);

# Parses whitespace and comments. **Note:** The yielded result is always
# ignored.
def tokWhitespace = {/
    [" " "\n"]
|
    "#" [! "\n"]* "\n"
|
    tokMultilineComment
/};

# Parses punctuation and operators. The lookahead is done to avoid bothering
# with the choice expression unless we have a definite match.
def tokPunctuation = {/
    &["\\-/%&|^!@:,.=+?;*<>{}()[]"]
    (
        "\\==" | "\\!=" | "\\<=" | "\\>=" | "\\<" | "\\>"
    |
        "&&&" | "|||" | "^^^" | "!!!" | "<<<" | ">>>" | "..!" | "..+"
    |
        "@@" | "::" | "<>" | "()" | "&&" | "||" | ".." | "{/" | "/}" |
        "==" | "!=" | "<=" | ">="
    |
        # Note: We check this error condition here instead of in the
        # comment parsing code, because comments get parsed as whitespace,
        # which gets ignored. Rather than changing to not-quite-ignore
        # whitespace -- which would be messy -- we instead notice `/*` here
        # where we're parsing other punctuation. This is clean but a little
        # non-obvious, hence this comment.
        "/*" .*
        { <> @[error: "Unterminated comment."] }
    |
        # Single-character punctuation / operator.
        .
    )
/};

# Parses a single binary digit (or spacer), returning its value.
def tokBinDigit = {/
    ch = ["_01"]
    { <> intFromDigitChar(ch) }
/};

# Parses a single decimal digit (or spacer), returning its value.
def tokDecDigit = {/
    ch = ["_" "0".."9"]
    { <> intFromDigitChar(ch) }
/};

# Parses a single hexadecimal digit (or spacer), returning its value.
def tokHexDigit = {/
    ch = ["_" "0".."9" "a".."f" "A".."F"]
    { <> intFromDigitChar(ch) }
/};

# Parses an integer literal.
def tokInt = {/
    baseSign = (
        "0x" ("-" { <> -16 } | { <> 16 })
    |
        "0b" ("-" { <> -2 } | { <> 2 })
    |
        { <> 10 }
    )

    digits = (
        { <> eq(baseSign, 10) }
        tokDecDigit+
    |
        { <> eq(iabs(baseSign), 16) }
        tokHexDigit+
    |
        { <> eq(iabs(baseSign), 2) }
        tokBinDigit+
    )

    { <> @[int: intFromDigitList(baseSign, digits)] }
/};

# Parses a single hexadecimal character. This is called during `\x...;`
# parsing.
def tokHexChar = {/
    digits = tokHexDigit+
    { <> stringFromInt(intFromDigitList(16, digits)) }
/};

# Parses a single entity-named character. This is called during `\&...;`
# parsing.
def tokNamedChar = {/
    chars = ["a".."z" "A".."Z" "0".."9" "."]+
    {
        def name = stringFromTokenList(chars);
        <> mapGet(ENTITY_MAP, name)
    }
/};

# Parses a single character, inside a quoted string.
def tokStringChar = {/
    (
        ch = [! "\\" "\"" "\n"]
        { <> tokenType(ch) }
    )
|
    # This is the rule that ignores spaces after newlines.
    "\n"
    " "*
    { <> "\n" }
|
    (
        "\\"
        (
            "\\" { <> "\\" } |
            "\"" { <> "\"" } |
            "n"  { <> "\n" } |
            "r"  { <> "\r" } |
            "t"  { <> "\t" } |
            "0"  { <> "\0" }
        |
            "/"  { <> "" }
        |
            # This is the rule that ignores the newline after end-of-line `\`.
            " "* "\n" " "*
            { <> "" }
        |
            "x"
            (
                first = tokHexChar
                more = ("," tokHexChar)*
                ";"
                { <> stringAdd(first, more*) }
            |
                { <> @[error: "Invalid hexadecimal character literal."] }
            )
        |
            "&"
            (
                first = tokNamedChar
                more = ("," tokNamedChar)*
                ";"
                { <> stringAdd(first, more*) }
            |
                { <> @[error: "Invalid named character literal."] }
            )
        |
            { <> @[error: "Invalid character literal escape sequence."] }
        )
    )
/};

# Parses a quoted string.
def tokString = {/
    "\""
    chars = tokStringChar*

    (
        "\""
        { <out> ::
            # Propagate any character parsing error outward.
            listForEach(chars)
                { ., ch :: ifIs { <> isToken(ch) } { <out> ch } };
            <> @[string: stringAdd(chars*)]
        }
    |
        { <> @[error: "Unterminated string literal."] }
    )
/};

# Parses an identifier (in the usual form). This also parses keywords.
def tokIdentifier = {/
    first = ["_" "a".."z" "A".."Z"]
    rest = ["_" "a".."z" "A".."Z" "0".."9"]*
    {
        def string = stringFromTokenList([first, rest*]);
        <> ifValue { <> mapGet(KEYWORDS, string) }
            { keyword :: <> keyword }
            { <> @[identifier: string] }
    }
/};

# Parses the quoted-string identifier form.
def tokQuotedIdentifier = {/
    "\\"
    s = tokString
    { <> @[identifier: tokenValue(s)] }
/};

# "Parses" an unrecognized character. This also consumes any further characters
# on the same line, in an attempt to resynch the input.
def tokError = {/
    badCh = .
    [! "\n"]*
    {
        def msg = format("Unrecognized character: %q", tokenType(badCh));
        <> @[error: msg]
    }
/};

# Parses an arbitrary token or error.
def tokToken = {/
    tokString | tokIdentifier | tokQuotedIdentifier
|
    # This needs to be listed after the quoted identifier rule, to
    # prevent `\"...` from being treated as a `\` token followed by
    # a string.
    tokPunctuation
|
    # This needs to be listed after the identifier rule, to prevent
    # an identifier-initial `_` from triggering this rule.
    tokInt
|
    tokError
/};

# Parses a file of tokens, yielding a list of them.
def tokFile = {/
    tokens=(tokWhitespace* tokToken)* tokWhitespace*
    { <> tokens }
/};


#
# Exported functions
#

# Documented in Samizdat Layer 1 spec.
fn sam2Tokenize(programText) {
    <> pegApply(tokFile, programText)
};

<> [
    sam2Tokenize: sam2Tokenize
]

# Copyright 2013 the Samizdat Authors (Dan Bornstein et alia).
# Licensed AS IS and WITHOUT WARRANTY under the Apache License,
# Version 2.0. Details: <http://www.apache.org/licenses/LICENSE-2.0>

#
# Samizdat Layer 2 Tree Parser
#


#
# Helper definitions
#

# Set-like map of all lowercase identifier characters. Used to figure
# out if we're looking at a keyword in the `identifierString` rule.
def LOWER_ALPHA = ["a".."z": true];

# Returns a `call` node.
fn makeCall(function, actuals*) {
    <> @[call: [function: function, actuals: actuals]]
};

# Returns a `varDef` node.
fn makeVarDef(name, value) {
    <> @[varDef: [name: name, value: value]]
};

# Returns a `varRef` node.
fn makeVarRef(name) {
    <> @[varRef: name]
};

# Returns a `call` node that names a function as a `varRef`.
fn makeCallName(name, actuals*) {
    <> @[call: [function: makeVarRef(name), actuals: actuals]]
};

# Returns a `literal` node.
fn makeLiteral(value) {
    <> @[literal: value]
};

# Returns a node representing a thunk (no-arg function) that returns the
# expression represented by the given node.
fn makeThunk(expression) {
    <> @[closure: [statements: [], yield: expression]]
};

# Returns a `call` node to a nonlocal exit with the given name and
# with optional expression value. The expression if supplied is automatically
# "thunked".
fn makeCallNonlocalExit(name, expression?) {
    <> ifValue { <> expression* }
        { ex :: <> makeCall(makeVarRef("nonlocalExit"), name, makeThunk(ex)) }
        { <> makeCall(makeVarRef("nonlocalExit"), name) }
};

# Returns a `call` node that names a function as a `varRef` and passes
# "thunked" versions of each of the given actual arguments.
fn makeCallNameThunks(name, actuals*) {
    def thunks = listMap(actuals) { ., one :: <> makeThunk(one) };
    <> makeCallName(name, thunks*)
};

# Map of token types to corresponding unary operator function name variable
# references.
def UNARY_OPERATORS = listReduce([:], ["+", "-", "&", "[]", "!!!"])
    { result, ., name ::
        <> [result*, (name): makeVarRef(stringAdd("unary", name))]
    };

# Map of token types to corresponding binary operator function name variable
# references.
def BINARY_OPERATORS = [
    (listReduce(
        [:],
        [
            "+", "-", "*", "/", "%",
            "&&&", "|||", "^^^", "<<<", ">>>",
            "==", "!=", "<", ">", "<=", ">=",
            "\\==", "\\!=", "\\<", "\\>", "\\<=", "\\>="
        ])
        { result, ., name ::
            <> [result*, (name): makeVarRef(stringAdd("binary", name))]
        })*,
    "..":  makeVarRef("makeRangeInclusive"),
    "..!": makeVarRef("makeRangeExclusive")
];

# Helper for parsing binary operator expressions, which puts together
# a sequence of function calls.
fn makeBinaryCalls(firstEx, opExList) {
    <> listReduce(firstEx, opExList) { result, ., opEx ::
        def op = listFirst(opEx);
        def ex = listLast(opEx);
        <> makeCall(mapGet(BINARY_OPERATORS, tokenType(op)), result, ex)
    }
};

# Reports the given list of pending tokens as part of error processing.
fn reportError(pending) {
    io0Note("Pending tokens:");

    listForEach(pending)
        { ., token :: io0Note(format("    %q", token)) };

    io0Die("\nExtra tokens at end of program.")
};


#
# Grammar rules
#

#
# Samizdat Layer 0 definitions
#

# Forward declarations.
def parseProgramBody = forwardFunction();
def parseExpression = forwardFunction();

# Forward declaration required for integrating layer 1 definitions.
def parseParser = forwardFunction();

# Parses a yield / non-local exit definition, yielding the def name.
def parseYieldDef = {/
    @"<"
    name = @identifier
    @">"
    { <> tokenValue(name) }
/};

# Parses an optional yield / non-local exit definition, always yielding
# a map (an empty map if no yield def was present).
def parseOptYieldDef = {/
    y = parseYieldDef
    { <> [yieldDef: y] }
|
    { <> [:] }
/};

# Parses a formal argument decalaration.
def parseFormal = {/
    name = (
        n = @identifier
        { <> [name: tokenValue(n)] }
    |
        @"." { <> [:] }
    )

    repeat = (
        r = [@"?" @"*" @"+"]
        { <> [repeat: tokenType(r)] }
    |
        { <> [:] }
    )

    { <> [:, name*, repeat*] }
/};

# Parses a list of formal arguments, with no surrounding parentheses.
def parseFormalsList = {/
    first = parseFormal
    rest = (@"," parseFormal)*
    { <> [formals: [first, rest*]] }
|
    { <> [:] }
/};

# Parses program / function declarations.
def parseProgramDeclarations = {/
    yieldDef = parseOptYieldDef
    formals = parseFormalsList

    @"::"

    { <> [:, formals*, yieldDef*] }
/};

# Parses a program (top-level program or contents inside function braces).
def parseProgram = {/
    decls = (parseProgramDeclarations | { <> [:] })
    body = parseProgramBody
    { <> @[closure: [:, decls*, body*]] }
/};

# Parses a closure (in-line anonymous function, with no extra bindings).
def parseClosure = {/
    @"{"
    prog = parseProgram
    @"}"
    { <> prog }
/};

# Parses a closure which must not define any formal arguments.
def parseNullaryClosure = {/
    c = parseClosure

    {
        ifIs { <> mapGet(tokenValue(c), "formals") }
            { io0Die("Invalid formal argument in code block.") };
        <> c
    }
/};

# Parses a closure which must have neither formal arguments nor a yield
# definition.
def parseCodeOnlyClosure = {/
    c = parseNullaryClosure

    {
        ifIs { <> mapGet(tokenValue(c), "yieldDef") }
            { io0Die("Invalid yield definition in code block.") };
        <> c
    }
/};

# Common parsing for `fn` statements and expressions. The syntax for
# both is identical, except that the statement form requires that the
# function be named. The result of this rule is a map identical in form to
# what's required for a closure payload, except that `name` may also
# be bound.
#
# The result of this rule is suitable for use as a `closure` node
# payload. And as long as `name` is bound, the result is valid to use
# as the payload for a `fnDef` node.
#
# The translation is along these lines:
#
# ```
# fn <out> name(arg1, arg2) { stat1; stat2 }
# ```
#
# ```
# { <\"return"> arg1, arg2 ::
#     def out = \"return";
#     stat1;
#     stat2
# }
# ```
#
# with:
#
# * no yield def binding statement if an explicit yield def was not present.
#
# * the key `name` bound to the function name, if a name was defined. (This
#   is not representable in lower-layer surface syntax.)
def parseFnCommon = {/
    @fn

    # This is a variable definition statement which binds the yield def
    # name to the `return` function, if there is in fact a yield def present.
    returnDef = (
        y = parseYieldDef
        { <> makeVarDef(y, makeVarRef("return")) }
    )?

    name = (
        n = @identifier
        { <> [name: tokenValue(n)] }
    |
        { <> [:] }
    )

    formals = (
        @"()"
        { <> [:] }
    |
        @"("
        f = parseFormalsList
        @")"
        { <> f }
    )

    code = parseCodeOnlyClosure

    {
        def codeMap = tokenValue(code);
        def statements = [returnDef*, mapGet(codeMap, "statements")*];
        <> [
            codeMap*, name*, formals*,
            yieldDef: "return",
            statements: statements
        ]
    }
/};

# Parses a `fn` definition statement. The syntax here is the same as
# what's recognized by `parseFnCommon`, except that the name is required.
# We don't error out (terminate the runtime) on a missing name, though, as
# that just means that we're looking at a legit `fn` expression, which will
# get successfully parsed by the `expression` alternative of `statement`.
def parseFnDef = {/
    funcMap = parseFnCommon

    {
        <> ifIs { <> mapGet(funcMap, "name") }
            { <> @[fnDef: funcMap] }
    }
/};

# Parses a `fn` (function with `return` binding) expression. The translation
# is as described in `parseFnCommon` (above) if the function is not given a
# name. If the function *is* given a name, the translation is along the
# following lines (so as to enable self-recursion):
#
# ```
# fn <out> name ...
# ```
#
# =>
#
# ```
# {
#     fn <out> name ...;
#     <> name
# }()
# ```
def parseFnExpression = {/
    funcMap = parseFnCommon
    closure = { <> @[closure: funcMap] }

    (
        name = { <> mapGet(funcMap, "name") }
        {
            def mainClosure = @[closure: [
                statements: [@[fnDef: funcMap]],
                yield: makeVarRef(name)
            ]];

            <> makeCall(mainClosure)
        }
    |
        { <> closure }
    )
/};

# Parses an integer literal.
def parseInt = {/
    i = @int
    { <> makeLiteral(tokenValue(i)) }
/};

# Parses a string literal.
def parseString = {/
    s = @string
    { <> makeLiteral(tokenValue(s)) }
/};

# Parses an identifier, identifier-like keyword, or string literal,
# returning a string literal in all cases.
def parseIdentifierString = {/
    s = [@identifier @string]
    { <> makeLiteral(tokenValue(s)) }
|
    token = .
    {
        <> ifVoid { <> tokenValue(token) }
            {
                def type = tokenType(token);
                def firstCh = stringNth(type, 0);
                <> ifIs { <> mapGet(LOWER_ALPHA, firstCh) }
                    { <> makeLiteral(type) }
            }
    }
/};

# Parses an "unadorned" (no bracketing) list. Yields a list (per se)
# of contents.
def parseUnadornedList = {/
    first = parseExpression
    rest = (@"," parseExpression)*
    { <> [first, rest*] }
|
    { <> [] }
/};

# Parses a list literal.
def parseList = {/
    @"["
    expressions = parseUnadornedList
    @"]"
    {
        <> ifIs { <> eq(expressions, []) }
            { <> makeLiteral([]) }
            { <> makeCallName("makeList", expressions*) }
    }
/};

# Parses an empty map literal.
def parseEmptyMap = {/
    @"[" @":" @"]"
    { <> makeLiteral([:]) }
/};

# Parses a mapping (element of a map).
def parseMapping = {/
    key = (
        k = parseIdentifierString
        @":"
        { <> k }
    |
        k = parseExpression
        @":"
        { <> k }
    )

    value = parseExpression
    { <> makeCallName("makeList", value, key) }
|
    map = parseExpression
    {
        # We do a check to make sure the given expression is an interpolate
        # (which is the only way it can be valid). Note that
        # `expression @"*"` won't do the trick, since by the time we're here,
        # if there was a `*` it would have become part of the expression.
        <> ifIs { <> eq(tokenType(map), "interpolate") }
            { <> tokenValue(map) }
    }
/};

# Parses a map literal.
def parseMap = {/
    @"["
    (@":" @",")?
    first = parseMapping
    rest = (@"," parseMapping)*
    @"]"
    { <> makeCallName("makeMap", first, rest*) }
/};

# Parses a token literal.
def parseToken = {/
    @"@"

    tokenArgs = (
        @"["
        type = parseIdentifierString
        value = (@":" parseExpression)?
        @"]"
        { <> [type, value*] }
    |
        @"["
        type = parseExpression
        value = (@":" parseExpression)?
        @"]"
        { <> [type, value*] }
    |
        type = parseIdentifierString
        { <> [type] }
    )

    { <> makeCallName("makeToken", tokenArgs*) }
/};

# Parses a uniqlet literal.
def parseUniqlet = {/
    @"@@"
    { <> makeCallName("makeUniqlet") }
/};

# Parses a variable reference.
def parseVarRef = {/
    name = @identifier
    { <> makeVarRef(tokenValue(name)) }
/};

# Parses a variable definition.
def parseVarDef = {/
    @def
    name = @identifier
    @"="
    ex = parseExpression
    { <> makeVarDef(tokenValue(name), ex) }
/};

# Parses a parenthesized expression.
def parseParenExpression = {/
    @"("
    ex = parseExpression
    @")"
    { <> @[expression: ex] }
/};

# Parses an atomic expression.
def parseAtom = {/
    parseVarRef | parseInt | parseString |
    parseList | parseEmptyMap | parseMap |
    parseUniqlet | parseToken | parseClosure | parseParenExpression |
    # Defined by Samizdat Layer 1.
    &@"{/" parseParser
/};

# Parses a list of "actual" (as opposed to formal) arguments to a function.
# Yields a list of expression nodes.
def parseActualsList = {/
    @"()"
    parseClosure*
|
    @"("
    normalActuals = parseUnadornedList
    @")"
    closureActuals = parseClosure*
    { <> [normalActuals*, closureActuals*] }
|
    parseClosure+
/};

# `prefixOperator` and `postfixOperator` from layer 0 are replaced with
# forwarded functions here. These are subsumed by more featureful layer 2
# definitions, below.
def parsePrefixOperator = forwardFunction();
def parsePostfixOperator = forwardFunction();

# Parses a unary expression. This is an atom, optionally surrounded on
# either side by any number of unary operators. Postfix operators
# take precedence over (are applied before) the prefix operators.
def parseUnaryExpression = {/
    prefixes = parsePrefixOperator*
    base = parseAtom
    postfixes = parsePostfixOperator*

    {
        def withPosts = listReduce(base, postfixes)
            { result, ., op :: <> op(result) };
        <> listReduce(withPosts, listReverse(prefixes))
            { result, ., op :: <> op(result) }
    }
/};

# Parses a range expression.
def parseRangeExpression = {/
    # To provide for more sensible error messages, this rule first accepts
    # arbitrarily chained range expressions, and then explicitly rejects
    # all but the four valid range variants and the fall-through of not
    # actually being a range.

    base = parseUnaryExpression
    opExes = (
        op = [@".." @"..!"]
        ex = parseUnaryExpression
        { <> [tokenType(op), ex] }
    )*

    { <out> ::
        ifIs { <> eq(opExes,[]) }
            { <out> base };

        def restSize = lowSize(opExes);

        ifIs { <> gt(restSize, 2) }
            { io0Die("Invalid chained range expression.") };

        def last = listLast(opExes);
        def lastOp = listNth(last, 0);
        def lastEx = listNth(last, 1);

        def increment = ifIs { <> eq(restSize, 2) }
            {
                def first = listFirst(opExes);
                def firstOp = listNth(first, 0);
                def firstEx = listNth(first, 1);

                ifIs { <> eq(firstOp, "..!") }
                    { io0Die("Invalid use of exclusive range operator.") };

                <> [firstEx]
            }
            { <> [] };

        <> makeCall(mapGet(BINARY_OPERATORS, lastOp), base, lastEx, increment*);
    }
/};

# `expression` from layer 0 is omitted here (it's forwarded earlier), and
# `statement` and `nonlocalExit` are replaced with forwarded functions here.
# These are all subsumed by more featureful layer 2 definitions, below.
def parseStatement = forwardFunction();
def parseNonlocalExit = forwardFunction();

# Parses a local yield / return.
def parseYield = {/
    @"<>"
    (
        ex = parseExpression
        { <> [yield: ex] }
    |
        { <> [:] }
    )
/};

# Parses a program body (statements plus optional yield).
def implProgramBody = {/
    @";"*

    most = (
        s = parseStatement
        @";"+
        { <> s }
    )*

    last = (
        s = (parseStatement | parseNonlocalExit)
        { <> [statements: [s]] }
    |
        y = parseYield
        { <> [statements: [], y*] }
    |
        { <> [statements: []] }
    )

    @";"*

    {
        def allStatements = [most*, mapGet(last, "statements")*];
        <> [last*, statements: allStatements]
    }
/};
parseProgramBody(implProgramBody);

# Top-level rule to parse a program with possible error afterwards.
# Note that an empty string is a valid program.
def parseProgramOrError = {/
    prog = parseProgram
    (
        pending = .+
        { reportError(pending) }
    )?
    { <> prog }
/};


#
# Samizdat Layer 1 definitions
#

# Forward declaration.
def parseChoicePex = forwardFunction();

# Parses a parser function.
def implParser = {/
    @"{/"
    pex = parseChoicePex
    @"/}"
    { <> @[parser: pex] }
/};
parseParser(implParser);

# Parses a parenthesized parsing expression.
def parseParenPex = {/
    @"("
    pex = parseChoicePex
    @")"
    { <> pex }
/};

# Parses a string literal parsing expression.
def parseParserString = {/
    s = @string
    {
        def value = tokenValue(s);
        <> ifIs { <> eq(lowSize(value), 1) }
            { <> @[token: value] }
            { <> s }
    }
/};

# Parses a token literal parsing expression.
def parseParserToken = {/
    @"@"
    type = parseIdentifierString
    { <> @[token: tokenValue(type)] }
/};

# Parses a string or character range parsing expression, used when defining
# sets.
def parseParserSetString = {/
    s = @string
    (
        @".."
        end = @string
        {
            def startChar = tokenValue(s);
            def endChar = tokenValue(end);
            <> ifIs
                { <> and
                    { <> eq(lowSize(startChar), 1) }
                    { <> eq(lowSize(endChar), 1) } }
                { <> @[string: stringAdd([startChar..endChar]*)] }
        }
    |
        { <> s }
    )
/};

# Parses a set (or set complement) parsing expression.
def parseParserSet = {/
    @"["

    type = (
        @"!" { <> "[!]" }
    |
        { <> "[]" }
    )

    terminals = (
        strings = parseParserSetString+
        {
            def oneString = listReduce("", strings)
                { result, ., s :: <> stringAdd(result, tokenValue(s)) };
            <> stringReduce([], oneString)
                { result, ., ch :: <> [result*, ch] }
        }
    |
        tokens = parseParserToken+
        { <> listMap(tokens) { ., t :: <> tokenValue(t) } }
    |
        { <> [] }
    )

    @"]"

    { <> @[(type): terminals] }
/};

# Parses a code block parsing expression.
def parseParserCode = {/
    closure = parseNullaryClosure
    { <> @["{}": tokenValue(closure) ] }
/};

# Parses a predicate parsing expression.
def parseParserPredicate = {/
    @"&&"
    predicate = parseParenExpression
    { <> @["&&": predicate] }
/};

# Parses an atomic parsing expression.
def parseParserAtom = {/
    parseVarRef
|
    parseParserString
|
    parseParserToken
|
    parseParserSet
|
    parseParserCode
|
    parseParserPredicate
|
    @"."
|
    @"()"
|
    parseParenPex
/};

# Parses a repeat (or not) parsing expression.
def parseRepeatPex = {/
    atom = parseParserAtom
    (
        repeat = [@"?" @"*" @"+"]
        { <> @[tokenType(repeat): atom] }
    |
        { <> atom }
    )
/};

# Parses a lookahead (or not) parsing expression. This covers both lookahead
# success and lookahead failure.
def parseLookaheadPex = {/
    (
        lookahead = [@"&" @"!"]
        pex = parseRepeatPex
        { <> @[tokenType(lookahead): pex] }
    )
|
    parseRepeatPex
/};

# Parses a name (or not) parsing expression.
def parseNamePex = {/
    (
        name = @identifier
        @"="
        pex = parseLookaheadPex
        { <> @[varDef: [name: tokenValue(name), value: pex]] }
    )
|
    parseLookaheadPex
/};

# Parses a sequence parsing expression. This includes sequences of length
# one, but it does *not* parse empty (zero-length) sequences.
def parseSequencePex = {/
    items = parseNamePex+
    { <> @[sequence: items] }
/};

# Parses a choice parsing expression. This includes a single choice.
def implChoicePex = {/
    first = parseSequencePex
    rest = (@"|" parseSequencePex)*
    { <> @[choice: [first, rest*]] }
/};
parseChoicePex(implChoicePex);


#
# Samizdat Layer 2 definitions
#

# Parses a non-local exit / return. All of the form matched by this rule
# have the dual properties of (a) necessarily being at the end of a code
# block, and (b) being represented as a function call in the underlying
# function representation of code blocks.
def implNonlocalExit = {/
    name = (
        @"<"
        n = parseVarRef
        @">"
        { <> n }
    |
        op = [@break @continue @return]
        { <> makeVarRef(tokenType(op)) }
    )

    value = (
        ex = parseExpression
        {
            # The test for a valued `continue` is done explicitly here
            # (rather than just letting the rule fail) in order to make the
            # error message more sensible.
            ifIs { <> eq(tokenValue(name), "continue") }
                { io0Die("Invalid use of continue with value.") };
            <> ex
        }
    )?

    { <> makeCallNonlocalExit(name, value*) }
/};
parseNonlocalExit(implNonlocalExit);

# Parses a unary prefix operator. This yields a function (per se) that
# takes a node and yields a call to the appropriate operator function.
def implPrefixOperator = {/
    operator = [@"+" @"-" @"&" @"!!!"]
    {
        def name = mapGet(UNARY_OPERATORS, tokenType(operator));
        <> { node :: <> makeCall(name, node) }
    }
|
    # The remainder of the prefix operators are all specially converted,
    # because they are control constructs and not simple function
    # applications.
    @"!"
    {
        <> { node ::
            <> makeCallNameThunks("ifVoid", node, makeLiteral(true))
        }
    }
|
    @"&&"
    {
        <> { node ::
            <> makeCallNameThunks("ifIs",
                node, makeLiteral(true), makeLiteral(false))
        }
    }
/};
parsePrefixOperator(implPrefixOperator);

# Parses a unary postfix operator. This yields a function (per se) to call
# in order to construct a node that represents the appropriate ultimate
# function call.
def implPostfixOperator = {/
    actuals = parseActualsList
    { <> { node :: <> makeCall(node, actuals*) } }
|
    # The lookahead failure here is to make the grammar prefer `*` to be
    # treated as a binary op.
    @"*" !parseExpression
    { <> { node :: <> @[interpolate: node] } }
|
    @"["
    exprs = parseUnadornedList
    @"]"

    (
        &&(eq(exprs, []))
        { io0Die("Missing index value(s) from index expression.") }
    )?

    {
        def function = mapGet(UNARY_OPERATORS, "[]");
        <> { node :: <> makeCall(function, node, exprs*) }
    }
|
    names = (@"." parseIdentifierString)+

    {
        def function = mapGet(UNARY_OPERATORS, "[]");
        <> { node :: <> makeCall(function, node, names*) }
    }
|
    @"?"
    {
        def thenClosure = @[closure: [
            formals: [[name: "value"]],
            statements: [],
            yield: makeCallName("makeList", makeVarRef("value"))
        ]];
        def elseClosure = makeThunk(makeLiteral([]));

        <> { node ::
            def nodeThunk = makeThunk(node);
            <> makeCallName("ifValue", nodeThunk, thenClosure, elseClosure)
        }
    }
/};
parsePostfixOperator(implPostfixOperator);

# Parses a multiplicative expression.
def parseMulExpression = {/
    firstEx = parseRangeExpression
    opExes = (
        op = [@"*" @"/" @"%" @"<<<" @">>>"]
        ex = parseRangeExpression
        { <> [op, ex] }
    )*

    { <> makeBinaryCalls(firstEx, opExes) }
/};

# Parses an additive expression.
def parseAddExpression = {/
    firstEx = parseMulExpression
    opExes = (
        op = [@"+" @"-" @"&&&" @"|||" @"^^^"]
        ex = parseMulExpression
        { <> [op, ex] }
    )*

    { <> makeBinaryCalls(firstEx, opExes) }
/};

# Parses a comparison expression. The syntax here is the mathematical
# style of `x < y < z` meaning `x < y && y < z`. This semantics
# falls naturally out of the left-associativity of the expression
# along with the value-or-void logic model, as defined by the language.
def parseCompareExpression = {/
    firstEx = parseAddExpression
    opExes = (
        op = [
            @"=="   @"!="   @"<"   @">"   @"<="   @">="
            @"\\==" @"\\!=" @"\\<" @"\\>" @"\\<=" @"\\>="
        ]
        ex = parseAddExpression
        { <> [op, ex] }
    )*

    { <> makeBinaryCalls(firstEx, opExes) }
/};

# Parses a short-circuit boolean-and expression.
def parseBooleanAndExpression = {/
    first = parseCompareExpression
    rest = (@"&&" parseCompareExpression)*

    (
        # Not actually a boolean-and expression.
        &&(eq(lowSize(rest), 0))
        { <> first }
    |
        { <> makeCallNameThunks("booleanAnd", first, rest*) }
    )
/};

# Parses a short-circuit boolean-or expression.
def parseBooleanOrExpression = {/
    first = parseBooleanAndExpression
    rest = (@"||" parseBooleanAndExpression)*

    (
        # Not actually a boolean-or expression.
        &&(eq(lowSize(rest), 0))
        { <> first }
    |
        { <> makeCallNameThunks("booleanOr", first, rest*) }
    )
/};

# Parses a short-circuit logical-and expression.
def parseLogicAndExpression = {/
    first = parseBooleanOrExpression
    rest = (@"&" parseBooleanOrExpression)*

    (
        # Not actually a logical-and expression.
        &&(eq(lowSize(rest), 0))
        { <> first }
    |
        { <> makeCallNameThunks("and", first, rest*) }
    )
/};

# Parses a short-circuit logical-or expression.
def parseLogicOrExpression = {/
    first = parseLogicAndExpression
    rest = (@"|" parseLogicAndExpression)*

    (
        # Not actually a logical-or expression.
        &&(eq(lowSize(rest), 0))
        { <> first }
    |
        { <> makeCallNameThunks("or", first, rest*) }
    )
/};

# Parses an if expression. With a single test, this translates into
# a call to `ifIs`. With multiple tests, this translates into a
# call to `ifChain`. In either case, if the expression has a yield
# def, the main call is wrapped in a thunk-call.
def parseIfExpression = {/
    @if
    yieldDef = parseOptYieldDef
    firstCondition = parseParenExpression
    firstThen = parseCodeOnlyClosure

    elseIfThens = (
        @else
        @if
        condition = parseParenExpression
        then = parseCodeOnlyClosure
        { <> [condition, then] }
    )*

    finalElse = (
        @else
        parseCodeOnlyClosure
    )?

    mainCall = (
        # Unchained if-then or if-then-else.
        &&(eq(lowSize(elseIfThens), 0))
        {
            <> makeCallName("ifIs",
                makeThunk(firstCondition), firstThen, finalElse*)
        }
    |
        # General chained form.
        {
            # Make separate conditions and thens arrays.
            def arrays = listReduce(
                [[makeThunk(firstCondition)], [firstThen]],
                elseIfThens)
                { result, ., one ::
                    def conditions = listFirst(result);
                    def thens = listLast(result);
                    def condition = makeThunk(listFirst(one));
                    def then = listLast(one);
                    <> [
                        [conditions*, condition],
                        [thens*, then]
                    ]
                };

            def conditions = makeCallName("makeList", listFirst(arrays)*);
            def thens = [listLast(arrays)*, finalElse*];

            <> makeCallName("ifChain", conditions, thens*);
        }
    )

    (
        # There was a yield def; wrap the whole thing in a thunk-call.
        &&(ne(yieldDef, [:]))
        {
            def mainClosure = @[closure: [
                yieldDef: mapValue(yieldDef),
                statements: [],
                yield: mainCall
            ]];

            <> makeCall(mainClosure)
        }
    |
        { <> mainCall }
    )
/};

# Parses the optional yield definition that's associated with the `break`
# exit of a loop. This always results in a list, which is empty if there
# is no yield definition present, or is a single-element list of an
# appropriate variable definition and assignment.
def parseOptBreakDef = {/
    (
        y = parseYieldDef
        { <> makeVarDef(y, makeVarRef("break")) }
    )?
/};

# Helper for switch expressions: Parse a regular case.
def parseSwitchCase = {/
    key = parseUnadornedList
    @":"
    code = parseCodeOnlyClosure
    { <> makeCallName("makeList", code, key*) }
/};

# Helper for switch expressions: Parse a default case.
def parseSwitchDefault = {/
    @default
    @":"
    parseCodeOnlyClosure
/};

# Parses a switch expression. The translation is along these lines:
#
# ```
# switch <out> (value) {
#     ex1: { stat1a; stat1b }
#     ex2: { stat2a; stat2b }
#     default: { statDefault }
# }
# ```
#
# =>
#
# ```
# { <\"break"> ::
#     def out = \"break";
#     <> \"switch"(
#         value,
#         [
#             (ex1): { stat1a; stat1b },
#             (ex2): { stat2a; stat2b }
#         ])
#         { statDefault }
# }
# ```
#
# with the initial break assignment omitted if there is no yield def,
# and with overrides of map keys switched around so the *first* key
# wins.
def parseSwitchExpression = {/
    @switch
    breakDef = parseOptBreakDef
    value = parseParenExpression

    @"{"

    cases1 = parseSwitchCase*
    optDefault = parseSwitchDefault?
    cases2 = parseSwitchCase*

    (
        # Detect double default clause as an explicit error.
        parseSwitchDefault
        { io0Die("Multiple default clauses.") }
    )?

    @"}"

    {
        def switchCall = makeCallName("switch",
            value,
            makeCallName("makeMapReversed", cases1*, cases2*),
            optDefault*);

        def mainClosure = @[closure: [
            yieldDef: "break",
            statements: [breakDef*],
            yield: switchCall
        ]];

        <> makeCall(mainClosure)
    }
/};


# Parses a while expression. The translation is along these lines:
#
# ```
# while <out> (expr) { <next> :: stat1; stat2 }
# ```
#
# =>
#
# ```
# { <\"break"> ::
#     def out = \"break";
#     loop { <\"continue"> ::
#         ifIs { <> expr }
#             { <next> :: stat1; stat2 }
#             { <\"break"> }
#     }
# }()
# ```
#
# with the initial break assignment omitted if there is no yield def.
def parseWhileExpression = {/
    @while
    breakDef = parseOptBreakDef
    condition = parseParenExpression
    code = parseNullaryClosure

    {
        def loopClosure = @[closure: [
            yieldDef: "continue",
            statements: [
                makeCallName("ifIs",
                    makeThunk(condition),
                    code,
                    makeThunk(makeCallNonlocalExit(makeVarRef("break"))))
            ]
        ]];

        def mainClosure = @[closure: [
            yieldDef: "break",
            statements: [breakDef*, makeCallName("loop", loopClosure)]
        ]];

        <> makeCall(mainClosure)
    }
/};

# Parses a do expression. The translation is along these lines:
#
# ```
# do <out> { <next> :: stat1; stat2 } while (expr)
# ```
#
# =>
#
# ```
# { <\"break"> ::
#     def out = \"break";
#     loop { <\"continue"> ::
#         { <next> :: stat1; stat2 }();
#         ifNot { <> expr }
#             { <\"break"> }
#     }
# }()
# ```
#
# with the initial break assignment omitted if there is no yield def, and
# with the `ifNot` statement omitted if there is no `while` at the end
# of the `do`.
def parseDoExpression = {/
    @do
    breakDef = parseOptBreakDef
    code = parseNullaryClosure
    condition = (
        @while
        ex = parseParenExpression
        {
            <> makeCallName("ifNot",
                makeThunk(ex),
                makeThunk(makeCallNonlocalExit(makeVarRef("break"))))
        }
    )?

    {
        def loopClosure = @[closure: [
            yieldDef: "continue",
            statements: [makeCall(code), condition*]
        ]];

        def mainClosure = @[closure: [
            yieldDef: "break",
            statements: [breakDef*, makeCallName("loop", loopClosure)]
        ]];

        <> makeCall(mainClosure)
    }
/};

# Parses a general expression.
def implExpression = {/
    # This one's the top level "regular-looking" expression (in that it
    # covers the territory of C-style expressions).
    parseLogicOrExpression
|
    # This one is only nominally "regular-looking" (in that not many C
    # family languages have function expressions).
    parseFnExpression
|
    # This one and the rest are "statement-like" expressions (in that they
    # look like corresponding statements from C-derived languages).
    parseIfExpression
|
    parseDoExpression
|
    parseSwitchExpression
|
    parseWhileExpression
/};
parseExpression(implExpression);

# Parses a statement.
def implStatement = {/
    parseVarDef | parseFnDef | parseExpression
/};
parseStatement(implStatement);


#
# Exported functions
#

# Documented in Samizdat Layer 1 spec.
fn sam2Tree(program) {
    def tokens = ifIs { <> isString(program) }
        { <> sam2Tokenize(program) }
        { <> program };

    <> pegApply(parseProgramOrError, tokens)
};

<> [
    sam2Tree: sam2Tree
]

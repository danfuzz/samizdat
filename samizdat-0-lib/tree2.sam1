# Copyright 2013 the Samizdat Authors (Dan Bornstein et alia).
# Licensed AS IS and WITHOUT WARRANTY under the Apache License,
# Version 2.0. Details: <http://www.apache.org/licenses/LICENSE-2.0>

#
# Samizdat Layer 2 Tree Parser
#


#
# Helper definitions
#

# Set-like map of all lowercase identifier characters. Used to figure
# out if we're looking at a keyword in the `identifierString` rule.
def LOWER_ALPHA = [
    generatorForInclusiveRange("a", 1, "z")*: true
];

# Returns a `call` node.
fn makeCall(function, actuals*) {
    <> @[call: [function: function, actuals: actuals]]
};

# Returns a `varDef` node.
fn makeVarDef(name, value) {
    <> @[varDef: [name: name, value: value]]
};

# Returns a `varRef` node.
fn makeVarRef(name) {
    <> @[varRef: name]
};

# Returns a `call` node that names a function as a `varRef`.
fn makeCallName(name, actuals*) {
    <> @[call: [function: makeVarRef(name), actuals: actuals]]
};

# Returns a `literal` node.
fn makeLiteral(value) {
    <> @[literal: value]
};

# Returns a node representing a thunk (no-arg function) that returns the
# expression represented by the given node.
fn makeThunk(expression) {
    <> @[closure: [statements: [], yield: expression]]
};

# Returns a `call` node to a nonlocal exit with the given name and
# with optional expression value. The expression if supplied is automatically
# "thunked".
fn makeCallNonlocalExit(name, expression?) {
    <> ifValue { <> expression* }
        { ex :: <> makeCall(makeVarRef("nonlocalExit"), name, makeThunk(ex)) }
        { <> makeCall(makeVarRef("nonlocalExit"), name) }
};

# Returns a `call` node that names a function as a `varRef` and passes
# "thunked" versions of each of the given actual arguments.
fn makeCallNameThunks(name, actuals*) {
    def thunks = listMap(actuals) { ., one :: <> makeThunk(one) };
    <> makeCallName(name, thunks*)
};

# Returns a `closure` node like the one given, except with the `formals`
# binding replaced with the given arguments. Each of the `formals`
# must be a formal argument map as described in the execution tree spec.
fn closureWithFormals(closure, formals*) {
    <> @[closure: [tokenValue(closure)*, formals: formals]]
};

fn closureWithYieldDef(closure, name) {
    <> @[closure: [tokenValue(closure)*, yieldDef: name]]
};

# A no-argument yield-void thunk.
def YIELD_VOID_THUNK = @[closure: [statements: []]];

# A single-argument yield-void function.
def YIELD_VOID_FN_1 = closureWithFormals(YIELD_VOID_THUNK, [:]);

# Map of token types to corresponding unary operator function name variable
# references.
def UNARY_OPERATORS = mapMap([
    "+":    "unary+",
    "-":    "unary-",
    "&":    "unary&",
    "[]":   "unary[]",
    "!!!":  "inot"
    ])
    { key, value :: <> makeVarRef(value) };

# Map of token types to corresponding binary operator function name variable
# references.
def BINARY_OPERATORS = mapMap([
    "+":    "binary+",
    "-":    "binary-",
    "*":    "binary*",
    "/":    "binary/",
    "%":    "binary%",
    "==":   "binary==",
    "!=":   "binary!=",
    "<":    "binary<",
    ">":    "binary>",
    "<=":   "binary<=",
    ">=":   "binary>=",
    "&&&":  "iand",
    "|||":  "ior",
    "^^^":  "ixor",
    "<<<":  "ishl",
    ">>>":  "ishr",
    "\\==": "eq",
    "\\!=": "ne",
    "\\<":  "lt",
    "\\>":  "gt",
    "\\<=": "le",
    "\\>=": "ge",
    "..":   "generatorForInclusiveRange",
    "..!":  "generatorForExclusiveRange",
    "..+":  "generatorForOpenRange"
    ])
    { key, value :: <> makeVarRef(value) };

# Helper for parsing binary operator expressions, which puts together
# a sequence of function calls.
fn makeBinaryCalls(firstEx, opExList) {
    <> listReduce(firstEx, opExList) { result, ., opEx ::
        def op = listFirst(opEx);
        def ex = listLast(opEx);
        <> makeCall(mapGet(BINARY_OPERATORS, tokenType(op)), result, ex)
    }
};

# Reports the given list of pending tokens as part of error processing.
fn reportError(pending) {
    io0Note("Pending tokens:");

    listForEach(pending)
        { ., token :: io0Note(stringAdd("    ", sourceString(token))) };

    io0Die("\nExtra tokens at end of program.")
};


#
# Grammar rules
#

#
# *Layer 0* rules.
#
# This section consists of the definitions required to implement *Layer 0*,
# with comments indicating the "hooks" for higher layers.
#

# Forward declaration required for layer 2.
def parInterpolatedString = forwardFunction();

# Forward declarations.
def parProgramBody = forwardFunction();
def parExpression = forwardFunction();

# Forward declaration required for integrating layer 1 definitions.
def parParser = forwardFunction();

# Parses a yield / non-local exit definition, yielding the def name.
def parYieldDef = {/
    @"<"
    name = @identifier
    @">"
    { <> tokenValue(name) }
/};

# Parses an optional yield / non-local exit definition, always yielding
# a map (an empty map if no yield def was present).
def parOptYieldDef = {/
    y = parYieldDef
    { <> [yieldDef: y] }
|
    { <> [:] }
/};

# Parses a formal argument decalaration.
def parFormal = {/
    name = (
        n = @identifier
        { <> [name: tokenValue(n)] }
    |
        @"." { <> [:] }
    )

    repeat = (
        r = [@"?" @"*" @"+"]
        { <> [repeat: tokenType(r)] }
    |
        { <> [:] }
    )

    { <> [:, name*, repeat*] }
/};

# Parses a list of formal arguments, with no surrounding parentheses.
def parFormalsList = {/
    first = parFormal
    rest = (@"," parFormal)*
    { <> [formals: [first, rest*]] }
|
    { <> [:] }
/};

# Parses program / function declarations.
def parProgramDeclarations = {/
    yieldDef = parOptYieldDef
    formals = parFormalsList

    @"::"

    { <> [:, formals*, yieldDef*] }
/};

# Parses a program (top-level program or contents inside function braces).
def parProgram = {/
    decls = (parProgramDeclarations | { <> [:] })
    body = parProgramBody
    { <> @[closure: [:, decls*, body*]] }
/};

# Parses a closure (in-line anonymous function, with no extra bindings).
def parClosure = {/
    @"{"
    prog = parProgram
    @"}"
    { <> prog }
/};

# Parses a closure which must not define any formal arguments. This is done
# by parsing an arbitrary closure and then verifying that it does not
# declare formals. This is preferable to not-including formal argument
# syntax, because (a) no rule wants to differentiate these cases (rules either
# want an arbitrary closure or a specifically-constrained kind); (b) it
# reduces redundancy in the syntax, and (c) the error case on the former
# would be more obscure (as in just something like "unexpected token" on
# the would-be formal argument).
def parNullaryClosure = {/
    c = parClosure

    {
        ifIs { <> mapGet(tokenValue(c), "formals") }
            { io0Die("Invalid formal argument in code block.") };
        <> c
    }
/};

# Parses a closure which must have neither formal arguments nor a yield
# definition. See `parseNullaryClosure` above for discussion.
def parCodeOnlyClosure = {/
    c = parNullaryClosure

    {
        ifIs { <> mapGet(tokenValue(c), "yieldDef") }
            { io0Die("Invalid yield definition in code block.") };
        <> c
    }
/};

# Common parsing for `fn` statements and expressions. The syntax for
# both is identical, except that the statement form requires that the
# function be named. The result of this rule is a map identical in form to
# what's required for a closure payload, except that `name` may also
# be bound.
#
# The result of this rule is suitable for use as a `closure` node
# payload. And as long as `name` is bound, the result is valid to use
# as the payload for a `fnDef` node.
#
# The translation is along these lines:
#
# ```
# fn <out> name(arg1, arg2) { stat1; stat2 }
# ```
# =>
# ```
# { <\"return"> arg1, arg2 ::
#     def out = \"return";
#     stat1;
#     stat2
# }
# ```
#
# with:
#
# * no yield def binding statement if an explicit yield def was not present.
#
# * the key `name` bound to the function name, if a name was defined. (This
#   is not representable in lower-layer surface syntax.)
def parFnCommon = {/
    @fn

    # This is a variable definition statement which binds the yield def
    # name to the `return` function, if there is in fact a yield def present.
    returnDef = (
        y = parYieldDef
        { <> makeVarDef(y, makeVarRef("return")) }
    )?

    name = (
        n = @identifier
        { <> [name: tokenValue(n)] }
    |
        { <> [:] }
    )

    formals = (
        @"()"
        { <> [:] }
    |
        @"("
        f = parFormalsList
        @")"
        { <> f }
    )

    code = parCodeOnlyClosure

    {
        def codeMap = tokenValue(code);
        def statements = [returnDef*, mapGet(codeMap, "statements")*];
        <> [
            codeMap*, name*, formals*,
            yieldDef: "return",
            statements: statements
        ]
    }
/};

# Parses a `fn` definition statement. The syntax here is the same as
# what's recognized by `parFnCommon`, except that the name is required.
# We don't error out (terminate the runtime) on a missing name, though, as
# that just means that we're looking at a legit `fn` expression, which will
# get successfully parsed by the `expression` alternative of `statement`.
def parFnDef = {/
    funcMap = parFnCommon

    {
        <> ifIs { <> mapGet(funcMap, "name") }
            { <> @[fnDef: funcMap] }
    }
/};

# Parses a `fn` (function with `return` binding) expression. The translation
# is as described in `parFnCommon` (above) if the function is not given a
# name. If the function *is* given a name, the translation is along the
# following lines (so as to enable self-recursion):
#
# ```
# fn <out> name ...
# ```
# =>
# ```
# {
#     fn <out> name ...;
#     <> name
# }()
# ```
def parFnExpression = {/
    funcMap = parFnCommon
    closure = { <> @[closure: funcMap] }

    (
        name = { <> mapGet(funcMap, "name") }
        {
            def mainClosure = @[closure: [
                statements: [@[fnDef: funcMap]],
                yield: makeVarRef(name)
            ]];

            <> makeCall(mainClosure)
        }
    |
        { <> closure }
    )
/};

# Parses an integer literal.
def parInt = {/
    i = @int
    { <> makeLiteral(tokenValue(i)) }
/};

# Parses a string literal.
def parString = {/
    s = @string
    { <> makeLiteral(tokenValue(s)) }
/};

# Parses an identifier, identifier-like keyword, or string literal,
# returning a string literal in all cases.
def parIdentifierString = {/
    s = [@identifier @string]
    { <> makeLiteral(tokenValue(s)) }
|
    token = .
    {
        <> ifVoid { <> tokenValue(token) }
            {
                def type = tokenType(token);
                def firstCh = stringNth(type, 0);
                <> ifIs { <> mapGet(LOWER_ALPHA, firstCh) }
                    { <> makeLiteral(type) }
            }
    }
/};

# Parses an "unadorned" (no bracketing) list. Yields a list (per se)
# of contents.
def parUnadornedList = {/
    first = parExpression
    rest = (@"," parExpression)*
    { <> [first, rest*] }
|
    { <> [] }
/};

# Parses a list literal.
def parList = {/
    @"["
    expressions = parUnadornedList
    @"]"
    {
        <> ifIs { <> eq(expressions, []) }
            { <> makeLiteral([]) }
            { <> makeCallName("makeList", expressions*) }
    }
/};

# Parses an empty map literal.
def parEmptyMap = {/
    @"[" @":" @"]"
    { <> makeLiteral([:]) }
/};

# Parses an "atomic" map key (as opposed to the parens-and-commas form).
def parMapKeyAtom = {/
    # The lookahead at the end of the rule is to ensure we are not looking
    # at a more complicated expression. `@","` and `@")"` are matched here,
    # so that this rule can stay the same in *Layer 2*.
    k = parIdentifierString
    &[@":" @"," @")"]
    { <> k }
|
    parExpression
/};

# Parses an arbitrary map key. Note: This rule is nontrivial in *Layer 2*.
def parMapKey = {/
    # Note: This clause is only active for a list of two or more items.
    # A single parenthesized item is properly covered by the second alternate.
    @"("
    firstKey = parMapKeyAtom
    moreKeys = (@"," parMapKeyAtom)+
    @")"
    { <> @[interpolate: makeCallName("makeList", firstKey, moreKeys*)] }
|
    parMapKeyAtom
/};

# Parses a mapping (element of a map).
def parMapping = {/
    key = parMapKey
    @":"
    value = parExpression
    { <> makeCallName("makeList", value, key) }
|
    map = parExpression
    {
        # We do a check to make sure the given expression is an interpolate
        # (which is the only way it can be valid). Note that
        # `expression @"*"` won't do the trick, since by the time we're here,
        # if there was a `*` it would have become part of the expression.
        <> ifIs { <> eq(tokenType(map), "interpolate") }
            { <> tokenValue(map) }
    }
/};

# Parses a map literal.
def parMap = {/
    @"["
    (@":" @",")?
    first = parMapping
    rest = (@"," parMapping)*
    @"]"
    { <> makeCallName("makeMap", first, rest*) }
/};

# Parses a token literal.
def parToken = {/
    @"@"

    tokenArgs = (
        @"["
        type = parIdentifierString
        value = (@":" parExpression)?
        @"]"
        { <> [type, value*] }
    |
        @"["
        type = parExpression
        value = (@":" parExpression)?
        @"]"
        { <> [type, value*] }
    |
        type = parIdentifierString
        { <> [type] }
    )

    { <> makeCallName("makeToken", tokenArgs*) }
/};

# Parses a uniqlet literal.
def parUniqlet = {/
    @"@@"
    { <> makeCallName("makeUniqlet") }
/};

# Parses a variable reference.
def parVarRef = {/
    name = @identifier
    { <> makeVarRef(tokenValue(name)) }
/};

# Parses a variable definition.
def parVarDef = {/
    @def
    name = @identifier
    @"="
    ex = parExpression
    { <> makeVarDef(tokenValue(name), ex) }
/};

# Parses a parenthesized expression.
def parParenExpression = {/
    @"("
    ex = parExpression
    @")"
    { <> @[expression: ex] }
/};

# Parses an atomic expression.
def parAtom = {/
    parVarRef | parInt | parString | parList | parEmptyMap | parMap |
    parToken | parUniqlet | parClosure | parParenExpression
|
    # Defined by *Samizdat Layer 1*. The lookahead is just to make it clear
    # that *Layer 1* can only be "activated" with that one specific token.
    &@"{/" parParser
|
    # Defined by *Samizdat Layer 2*.
    &@interpolatedString parInterpolatedString
/};

# Parses a list of "actual" (as opposed to formal) arguments to a function.
# Yields a list of expression nodes.
def parActualsList = {/
    @"()"
    parClosure*
|
    @"("
    normalActuals = parUnadornedList
    @")"
    closureActuals = parClosure*
    { <> [closureActuals*, normalActuals*] }
|
    parClosure+
/};

# `prefixOperator` and `postfixOperator` from layer 0 are replaced with
# forwarded functions here. These are subsumed by more featureful layer 2
# definitions, below.
def parPrefixOperator = forwardFunction();
def parPostfixOperator = forwardFunction();

# Parses a unary expression. This is an atom, optionally surrounded on
# either side by any number of unary operators. Postfix operators
# take precedence over (are applied before) the prefix operators.
def parUnaryExpression = {/
    prefixes = parPrefixOperator*
    base = parAtom
    postfixes = parPostfixOperator*

    {
        def withPosts = listReduce(base, postfixes)
            { result, ., op :: <> op(result) };
        <> listReduce(withPosts, listReverse(prefixes))
            { result, ., op :: <> op(result) }
    }
/};

# `expression` from layer 0 is omitted here (it's forwarded earlier), and
# `statement` and `nonlocalExit` are replaced with forwarded functions here.
# These are all subsumed by more featureful layer 2 definitions, below.
def parStatement = forwardFunction();
def parNonlocalExit = forwardFunction();

# Parses a local yield / return.
def parYield = {/
    @"<>"
    (
        ex = parExpression
        { <> [yield: ex] }
    |
        { <> [:] }
    )
/};

# Parses a program body (statements plus optional yield).
def implProgramBody = {/
    @";"*

    most = (
        s = parStatement
        @";"+
        { <> s }
    )*

    last = (
        s = (parStatement | parNonlocalExit)
        { <> [statements: [s]] }
    |
        y = parYield
        { <> [statements: [], y*] }
    |
        { <> [statements: []] }
    )

    @";"*

    {
        def allStatements = [most*, mapGet(last, "statements")*];
        <> [last*, statements: allStatements]
    }
/};
parProgramBody(implProgramBody);

# Top-level rule to parse a program with possible error afterwards.
# Note that an empty string is a valid program.
def parProgramOrError = {/
    prog = parProgram
    (
        pending = .+
        { reportError(pending) }
    )?
    { <> prog }
/};


#
# *Layer 1* rules.
#
# This section consists of the definitions required to implement *Layer 1*,
# above and beyond the preceding section.
#
# **Note:** The grammar uses the label "pex" to denote various
# "Parser EXpression" types.
#

# Forward declaration.
def parChoicePex = forwardFunction();

# Parses a parser function.
def implParser = {/
    @"{/"
    pex = parChoicePex
    @"/}"
    { <> @[parser: pex] }
/};
parParser(implParser);

# Parses a parenthesized parsing expression.
def parParenPex = {/
    @"("
    pex = parChoicePex
    @")"
    { <> pex }
/};

# Parses a string literal parsing expression.
def parParserString = {/
    s = @string
    {
        def value = tokenValue(s);
        <> ifIs { <> eq(lowSize(value), 1) }
            { <> @[token: value] }
            { <> s }
    }
/};

# Parses a token literal parsing expression.
def parParserToken = {/
    @"@"
    type = parIdentifierString
    { <> @[token: tokenValue(type)] }
/};

# Parses a string or character range parsing expression, used when defining
# sets.
def parParserSetString = {/
    s = @string
    (
        @".."
        end = @string
        {
            def startChar = tokenValue(s);
            def endChar = tokenValue(end);
            <> ifIs
                { <> and
                    { <> eq(lowSize(startChar), 1) }
                    { <> eq(lowSize(endChar), 1) } }
                {
                    def charGen =
                        generatorForInclusiveRange(startChar, 1, endChar);
                    <> @[string: stringAdd(charGen*)]
                }
        }
    |
        { <> s }
    )
/};

# Parses a set (or set complement) parsing expression.
def parParserSet = {/
    @"["

    type = (
        @"!" { <> "[!]" }
    |
        { <> "[]" }
    )

    terminals = (
        strings = parParserSetString+
        {
            def oneString = listReduce("", strings)
                { result, ., s :: <> stringAdd(result, tokenValue(s)) };
            <> stringReduce([], oneString)
                { result, ., ch :: <> [result*, ch] }
        }
    |
        tokens = parParserToken+
        { <> listMap(tokens) { ., t :: <> tokenValue(t) } }
    |
        { <> [] }
    )

    @"]"

    { <> @[(type): terminals] }
/};

# Parses a code block parsing expression.
def parParserCode = {/
    closure = parNullaryClosure
    { <> @["{}": tokenValue(closure) ] }
/};

# Parses a predicate parsing expression.
def parParserPredicate = {/
    @"&&"
    predicate = parParenExpression
    { <> @["&&": predicate] }
/};

# Parses an atomic parsing expression.
def parParserAtom = {/
    @"." | @"()" |
    parVarRef | parParserString | parParserToken | parParserSet |
    parParserCode | parParserPredicate | parParenPex
/};

# Parses a repeat (or not) parsing expression.
def parRepeatPex = {/
    atom = parParserAtom
    (
        repeat = [@"?" @"*" @"+"]
        { <> @[tokenType(repeat): atom] }
    |
        { <> atom }
    )
/};

# Parses a lookahead (or not) parsing expression. This covers both lookahead
# success and lookahead failure.
def parLookaheadPex = {/
    (
        lookahead = [@"&" @"!"]
        pex = parRepeatPex
        { <> @[tokenType(lookahead): pex] }
    )
|
    parRepeatPex
/};

# Parses a name (or not) parsing expression.
def parNamePex = {/
    (
        name = @identifier
        @"="
        pex = parLookaheadPex
        { <> @[varDef: [name: tokenValue(name), value: pex]] }
    )
|
    parLookaheadPex
/};

# Parses a sequence parsing expression. This includes sequences of length
# one, but it does *not* parse empty (zero-length) sequences.
def parSequencePex = {/
    items = parNamePex+
    { <> @[sequence: items] }
/};

# Parses a choice parsing expression. This includes a single choice.
def implChoicePex = {/
    first = parSequencePex
    rest = (@"|" parSequencePex)*
    { <> @[choice: [first, rest*]] }
/};
parChoicePex(implChoicePex);


#
# Samizdat Layer 2 definitions
#

# Helper for `?` postfix and string interpolation: Construct an optional-value
# expression. This is approximately:
#
# ```
# ifValue { <> node }
#     { value :: <> [value] }
#     { <> [] }
# ```
fn makeOptValueExpression(node) {
    def thenClosure = @[closure: [
        formals: [[name: "value"]],
        statements: [],
        yield: makeCallName("makeList", makeVarRef("value"))
    ]];
    def elseClosure = makeThunk(makeLiteral([]));

    <> makeCallName("ifValue", makeThunk(node), thenClosure, elseClosure)
};

# Helper for string interpolation: Parses the two kinds of interpolation,
# yielding an appropriate expression node if syntactically valid, including
# verification that all input was consumed.
def parStringInterpolation = {/
    &@"("
    ex = parAtom
    !.
    { <> ex }
|
    &@"{"
    block = parNullaryClosure
    !.
    { <> makeCall(block) }
/};

# Parses an interpolated string. The payload of an interpolated string
# token is a list with elements being either simple strings or lists of
# tokens. The token lists are delimited either with parentheses or braces.
# Parenthesized lists are taken to be expressions to be evaluated. Braced
# lists are taken to be thunks to be evaluated-and-called. The translation
# is along these lines:
#
# ```
# @[interpolatedString: [
#     "string",
#     [format: "formatStr", tokens: [@"(", exprToken, ..., @")"]],
#     [format: "formatStr", tokens: [@"{", blockToken, ..., @"}"]]
# ]]
# ```
# =>
# ```
# stringAdd("string", fmt1((expr...)?*), fmt2({ block... }()?*))
# ```
#
def implInterpolatedString = {/
    token = @interpolatedString

    {
        # Convert each of the payload items into the proper form.
        # This includes recursive parser calls to convert list forms
        # into appropriate node types.
        def elems = listMap(tokenValue(token)) { ., elem ::
            <> ifIs { <> isString(elem) }
                { <> makeLiteral(elem) }
                {
                    def tokens = mapGet(elem, "tokens");

                    def formatter = ifValue { <> mapGet(elem, "format") }
                        { format ::
                            <> makeCallName("formatterFromString",
                                makeLiteral(format))
                        }
                        { <> makeVarRef("stringFromValue") };

                    def call = ifValue
                        { <> pegApply(parStringInterpolation, tokens) }
                        { ex :: <> ex }
                        { io0Die("Invalid syntax in string interpolation.") };

                    <> makeCall(formatter,
                        @[interpolate: makeOptValueExpression(call)])
                }
        };

        <> makeCallName("stringAdd", elems*)
    }
/};
parInterpolatedString(implInterpolatedString);

# Parses a non-local exit / return. All of the form matched by this rule
# have the dual properties of (a) necessarily being at the end of a code
# block, and (b) being represented as a function call in the underlying
# function representation of code blocks.
def implNonlocalExit = {/
    name = (
        @"<"
        n = parVarRef
        @">"
        { <> n }
    |
        op = [@break @continue @return]
        { <> makeVarRef(tokenType(op)) }
    )

    value = (
        ex = parExpression
        {
            # The test for a valued `continue` is done explicitly here
            # (rather than just letting the rule fail) in order to make the
            # error message more sensible.
            ifIs { <> eq(tokenValue(name), "continue") }
                { io0Die("Invalid use of continue with value.") };
            <> ex
        }
    )?

    { <> makeCallNonlocalExit(name, value*) }
/};
parNonlocalExit(implNonlocalExit);

# Parses a unary prefix operator. This yields a function (per se) that
# takes a node and yields a call to the appropriate operator function.
def implPrefixOperator = {/
    operator = [@"+" @"-" @"&" @"!!!"]
    {
        def name = mapGet(UNARY_OPERATORS, tokenType(operator));
        <> { node :: <> makeCall(name, node) }
    }
|
    # The remainder of the prefix operators are all specially converted,
    # because they are control constructs and not simple function
    # applications.
    @"!"
    {
        <> { node ::
            <> makeCallNameThunks("ifNot", node, makeLiteral(true))
        }
    }
|
    @"&&"
    {
        <> { node ::
            <> makeCallNameThunks("ifIs",
                node, makeLiteral(true), makeLiteral(false))
        }
    }
/};
parPrefixOperator(implPrefixOperator);

# Parses a unary postfix operator. This yields a function (per se) to call
# in order to construct a node that represents the appropriate ultimate
# function call.
def implPostfixOperator = {/
    actuals = parActualsList
    { <> { node :: <> makeCall(node, actuals*) } }
|
    # The lookahead failure here is to make the grammar prefer `*` to be
    # treated as a binary op.
    @"*" !parExpression
    { <> { node :: <> @[interpolate: node] } }
|
    @"["
    exprs = parUnadornedList
    @"]"

    (
        { <> eq(exprs, []) }
        { io0Die("Missing index value(s) from index expression.") }
    )?

    {
        def function = mapGet(UNARY_OPERATORS, "[]");
        <> { node :: <> makeCall(function, node, exprs*) }
    }
|
    names = (@"." parIdentifierString)+

    {
        def function = mapGet(UNARY_OPERATORS, "[]");
        <> { node :: <> makeCall(function, node, names*) }
    }
|
    @"?"
    { <> { node :: <> makeOptValueExpression(node) } }
/};
parPostfixOperator(implPostfixOperator);

# Parses a range expression.
def parRangeExpression = {/
    base = parUnaryExpression

    increment = (
        @".."
        inc = parUnaryExpression
        &[@".." @"..!" @"..+"] # So increment won't match a limit expression.
        { <> inc }
    |
        # Note: This (arguably pointlessly) gets evaluated and yielded
        # even when not parsing a range expression.
        { <> makeLiteral(1) }
    )

    result = (
        op = [@".." @"..!"]
        limit = parUnaryExpression
        {
            <> makeCall(mapGet(BINARY_OPERATORS, tokenType(op)),
                base, increment, limit)
        }
    |
        @"..+"
        { <> makeCall(mapGet(BINARY_OPERATORS, "..+"), base, increment) }
    |
        { <> base }
    )

    (
        # Any additional range-ish operators cause an explicit error.
        [@".." @"..!" @"..+"]
        { io0Die("Invalid form for range expression.") }
    )?

    { <> result }
/};

# Parses a multiplicative expression.
def parMulExpression = {/
    firstEx = parRangeExpression
    opExes = (
        op = [@"*" @"/" @"%" @"<<<" @">>>"]
        ex = parRangeExpression
        { <> [op, ex] }
    )*

    { <> makeBinaryCalls(firstEx, opExes) }
/};

# Parses an additive expression.
def parAddExpression = {/
    firstEx = parMulExpression
    opExes = (
        op = [@"+" @"-" @"&&&" @"|||" @"^^^"]
        ex = parMulExpression
        { <> [op, ex] }
    )*

    { <> makeBinaryCalls(firstEx, opExes) }
/};

# Parses a comparison expression. The syntax here is the mathematical
# style of `x < y < z` meaning `x < y && y < z`. This semantics
# falls naturally out of the left-associativity of the expression
# along with the value-or-void logic model, as defined by the language.
def parCompareExpression = {/
    firstEx = parAddExpression
    opExes = (
        op = [
            @"=="   @"!="   @"<"   @">"   @"<="   @">="
            @"\\==" @"\\!=" @"\\<" @"\\>" @"\\<=" @"\\>="
        ]
        ex = parAddExpression
        { <> [op, ex] }
    )*

    { <> makeBinaryCalls(firstEx, opExes) }
/};

# Parses a short-circuit boolean-and expression.
def parBooleanAndExpression = {/
    first = parCompareExpression
    rest = (@"&&" parCompareExpression)*

    (
        # Not actually a boolean-and expression.
        { <> eq(lowSize(rest), 0) }
        { <> first }
    |
        { <> makeCallNameThunks("booleanAnd", first, rest*) }
    )
/};

# Parses a short-circuit boolean-or expression.
def parBooleanOrExpression = {/
    first = parBooleanAndExpression
    rest = (@"||" parBooleanAndExpression)*

    (
        # Not actually a boolean-or expression.
        { <> eq(lowSize(rest), 0) }
        { <> first }
    |
        { <> makeCallNameThunks("booleanOr", first, rest*) }
    )
/};

# Parses a short-circuit logical-and expression.
def parLogicAndExpression = {/
    first = parBooleanOrExpression
    rest = (@"&" parBooleanOrExpression)*

    (
        # Not actually a logical-and expression.
        { <> eq(lowSize(rest), 0) }
        { <> first }
    |
        { <> makeCallNameThunks("and", first, rest*) }
    )
/};

# Parses a short-circuit logical-or expression.
def parLogicOrExpression = {/
    first = parLogicAndExpression
    rest = (@"|" parLogicAndExpression)*

    (
        # Not actually a logical-or expression.
        { <> eq(lowSize(rest), 0) }
        { <> first }
    |
        { <> makeCallNameThunks("or", first, rest*) }
    )
/};

# Parses a parenthesized test clause, yielding a map of the form
# @[formal: ..., test: ...], with `formal` bound to a formal argument
# declaration and `test` bound to the test expression. If no formal was
# parsed, `formal` is bound to `[:]`.
def parTestClause = {/
    @"("

    formal = (
        name = @identifier
        @"="
        { <> [name: tokenValue(name)] }
    |
        { <> [:] }
    )

    test = parExpression
    @")"

    { <> [formal: formal, test: test] }
/};

# Parses an if expression. The translation is along the lines of:
#
# ```
# if <out> (name1 = expr1) {
#     thenStat1
# } else if (name2 = expr2) {
#     thenStat2
# } else {
#     elseStat
# }
# ```
# =>
# ```
# { <out> ::
#     <> ifValue { <> expr1 }
#         { name1 :: thenStat1 }
#         {
#             ifValue { <> expr2 }
#                 { name2 :: thenStat2 }
#                 { elseStat }
#         }
# }()
# ```
#
# with:
# * the outer thunk-call omitted if there was no yield definition.
# * the `elseStat` block as `{}` (that is yield-void) if there was no
#   `else` clause.
# * the then-clause argument declarations changed to `.` for any
#   clause where no name binding was present.
# * arbitrary nesting of additional clauses.
def parIfExpression = {/
    @if
    yieldDef = parOptYieldDef
    firstCondition = parTestClause
    firstThen = parCodeOnlyClosure

    elseIfThens = (
        @else
        @if
        condition = parTestClause
        then = parCodeOnlyClosure
        { <> [condition*, then: then] }
    )*

    finalElse = (
        @else
        parCodeOnlyClosure
    |
        { <> YIELD_VOID_THUNK }
    )

    mainThunk = {
        # This builds the full expression from back to front (inner to outer).
        def clauses = listReverse(
            [[firstCondition*, then: firstThen], elseIfThens*]);

        # To keep things simple, partial results are always thunks, so that
        # they can be slotted directly into place as the third argument to
        # an enclosing `ifValue`. At the end -- in the choice clause below --
        # we either add a yield def to the thunk and make wrap it in a call,
        # or unwrap it into a straight call, depending on if the original
        # `if` has a yield def or not.
        <> listReduce(finalElse, clauses) { result, ., clause ::
            def formal = mapGet(clause, "formal");
            def test = mapGet(clause, "test");
            def then = mapGet(clause, "then");
            <> makeThunk(
                makeCallName("ifValue",
                    makeThunk(test),
                    closureWithFormals(then, formal),
                    result))
        }
    }

    (
        # There was a yield def. Add the yield def to the thunk, and wrap
        # that in a call.
        { <> ne(yieldDef, [:]) }
        {
            def mainClosure =
                closureWithYieldDef(mainThunk, mapValue(yieldDef));
            <> makeCall(mainClosure)
        }
    |
        { <> mapGet(tokenValue(mainThunk), "yield") }
    )
/};

# Parses the optional yield definition that's associated with the `break`
# exit of a loop. This always results in a list, which is empty if there
# is no yield definition present, or is a single-element list of an
# appropriate variable definition and assignment.
def parOptBreakDef = {/
    (
        y = parYieldDef
        { <> makeVarDef(y, makeVarRef("break")) }
    )?
/};

# Helper for switch expressions: Parse a single case, including
# `default` and `else` cases. Returns a map that binds `keys` and
# `code`.
def parSwitchCase = {/
    keys = (
        [@default @else]
    |
        k = parMapKey
        { <> @[expression: k] }
    )

    @":"
    code = parCodeOnlyClosure

    { <> [code: code, keys: keys] }
/};

# Tree for the second argument to the `ifValue` inside a `switch` translation.
# This expression is constant across all switches, and it's most easily
# constructed by using the built-in parser.
def SWITCH_DISPATCH_CLOSURE = sam0Tree("
    args ::
    <> { cases, defaultFunction, value ::
        <> ifValue { <> mapGet(cases, value) }
            { function :: <> function(value) }
            { <> defaultFunction(value) }
    }(args*)");

# Parses a switch expression. The translation is along these lines:
#
# ```
# switch <out> (name = test) {
#     ex1: { stat1a; stat1b }
#     ex2: { stat2a; stat2b }
#     default: { statDefault }
#     else: { statElse }
# }
# ```
# =>
# ```
# { <\"break"> ::
#     def out = \"break";
#     <> ifValue
#         {
#             <> [
#                 [
#                     (ex1): { name :: stat1a; stat1b },
#                     (ex2): { name :: stat2a; stat2b }
#                 ],
#                 { name :: statDefault },
#                 test
#             ]
#         }
#         { args ::
#             <> { cases, defaultFunction, value ::
#                 <> ifValue { <> mapGet(cases, value) }
#                     { function :: <> function(value) }
#                     { <> defaultFunction(value) }
#             }(args*)
#         }
#         { statElse }
# }()
# ```
#
# with:
# * The initial break assignment omitted if there is no yield def.
# * Overrides of map keys switched around so the *first* key wins.
# * The `statElse` block omitted if there is no `else` clause.
# * The `statDefault` block replaced with `{ . :: }` (that is, a yield-void
#   one-arg function) if there is no `default` clause.
# * the consequent closure argument declarations changed to `.` for any
#   if no name binding was present.
#
# Note that the translation here is arranged so that the expressions to
# evaluate and all the case bodies only see the expected variable bindings,
# and not any "implementation detail" local variables.
def parSwitchExpression = {/
    @switch
    breakDef = parOptBreakDef
    testClause = parTestClause

    @"{"

    cases = parSwitchCase*

    @"}"

    {
        def formal = mapGet(testClause, "formal");
        def test = mapGet(testClause, "test");

        def optDefault = listMap(cases) { ., case ::
            <> ifIs { <> eq(mapGet(case, "keys"), @default) }
                { <> closureWithFormals(mapGet(case, "code"), formal) }
        };

        def optElse = listMap(cases) { ., case ::
            <> ifIs { <> eq(mapGet(case, "keys"), @else) }
                { <> mapGet(case, "code") }
        };

        def regularCases = listMap(cases) { ., case ::
            def keys = mapGet(case, "keys");
            <> ifIs { <> eq(tokenType(keys), "expression") }
                {
                    <> makeCallName("makeList",
                        closureWithFormals(mapGet(case, "code"), formal),
                        tokenValue(keys))
                }
        };

        ifIs { <> gt(lowSize(optDefault), 1) }
            { io0Die("Multiple default cases in switch.") };

        ifIs { <> gt(lowSize(optElse), 1) }
            { io0Die("Multiple else cases in switch.") };

        # Note: The `test` is wrapped in an expression node to prevent
        # interpolation expressions from being misinterpreted as argument
        # interpolation into the `makeList` function call being constructed.
        def testBody = makeThunk(
                makeCallName("makeList",
                    makeCallName("makeMapReversed", regularCases*),
                    ifValue { <> optDefault* }
                        { value :: <> closureWithFormals(value, formal) }
                        { <> YIELD_VOID_FN_1 },
                    @[expression: test]));

        def ifCall = makeCallName("ifValue",
            testBody,
            SWITCH_DISPATCH_CLOSURE,
            optElse*);

        def mainClosure = @[closure: [
            yieldDef: "break",
            statements: [breakDef*],
            yield: ifCall
        ]];

        <> makeCall(mainClosure)
    }
/};


# Parses a while expression. The translation is along these lines:
#
# ```
# while <out> (name = test) { <next> :: stat1; stat2 }
# ```
# =>
# ```
# { <\"break"> ::
#     def out = \"break";
#     loop { <\"continue"> ::
#         ifValue { <> test }
#             { <next> name :: stat1; stat2 }
#             { <\"break"> }
#     }
# }()
# ```
#
# with:
# * the initial break assignment omitted if there is no yield def.
# * the body argument declaration changed to `.` if there is no
#   test expression name binding.
def parWhileExpression = {/
    @while
    breakDef = parOptBreakDef
    testClause = parTestClause
    code = parNullaryClosure

    {
        def formal = mapGet(testClause, "formal");
        def test = mapGet(testClause, "test");

        def loopClosure = @[closure: [
            yieldDef: "continue",
            statements: [
                makeCallName("ifValue",
                    makeThunk(test),
                    closureWithFormals(code, formal),
                    makeThunk(makeCallNonlocalExit(makeVarRef("break"))))
            ]
        ]];

        def mainClosure = @[closure: [
            yieldDef: "break",
            statements: [breakDef*, makeCallName("loop", loopClosure)]
        ]];

        <> makeCall(mainClosure)
    }
/};

# Parses a do expression. The translation is along these lines:
#
# ```
# do <out> { <next> :: stat1; stat2 } while (expr)
# ```
# =>
# ```
# { <\"break"> ::
#     def out = \"break";
#     loop { <\"continue"> ::
#         { <next> :: stat1; stat2 }();
#         ifValue { <> expr }
#             { . :: }
#             { <\"break"> }
#     }
# }()
# ```
#
# with the initial break assignment omitted if there is no yield def, and
# with the `ifNot` statement omitted if there is no `while` at the end
# of the `do`.
def parDoExpression = {/
    @do
    breakDef = parOptBreakDef
    code = parNullaryClosure
    condition = (
        @while
        ex = parParenExpression
        {
            <> makeCallName("ifValue",
                makeThunk(ex),
                YIELD_VOID_FN_1,
                makeThunk(makeCallNonlocalExit(makeVarRef("break"))))
        }
    )?

    {
        def loopClosure = @[closure: [
            yieldDef: "continue",
            statements: [makeCall(code), condition*]
        ]];

        def mainClosure = @[closure: [
            yieldDef: "break",
            statements: [breakDef*, makeCallName("loop", loopClosure)]
        ]];

        <> makeCall(mainClosure)
    }
/};

# Parses a single generator definition, yielding a map of the form
# @[init: ..., formal: ...], with `init` bound to an initializer
# expression and `formal` bound to a formal argument declaration.
def parGeneratorDef = {/
    formal = (
        name = @identifier
        { <> [name: tokenValue(name)] }
    |
        "."
        { <> [:] }
    )

    @in
    init = parExpression

    { <> [formal: formal, init: init] }
/};

# Parses a parenthesized generator clause, yielding a map of the form
# @[formals: ..., init: ...], with `formals` bound to a formal
# argument declaration corresponding to the names given to each of the
# generators, and `init` bound to an initializer expression that yields a
# para-generator.
def parGeneratorClause = {/
    @"("
    firstGen = parGeneratorDef
    moreGens = ("," parGeneratorDef)*
    @")"

    {
        def gens = [firstGen, moreGens*];
        def formals = listMap(gens) { ., gen :: <> mapGet(gen, "formal") };
        def inits = listMap(gens) { ., gen :: <> mapGet(gen, "init") };
        def init = makeCallName("paraGeneratorFromValues", inits*);

        <> [formals: formals, init: init]
    }
/};

# Tree for the second argument to the `loopReduce` inside a `for` translation.
# This expression is constant across all `for` loops, and it's most easily
# constructed by using the built-in parser.
def FOR_BODY_CLOSURE = sam0Tree("
    generator ::
    def box = yieldBox();
    <> ifValue { <> generator(box) }
        { nextGenerator ::
            body(boxGet(box)*);
            <> nextGenerator
        }
        { <\\\"break\"> }");

# Parses a for expression. The translation is along these lines:
#
# ```
# for <out> (name1 in expr1, name2 in expr2) { <next> :: stat1; stat2 }
# ```
# =>
# ```
# { <\"break"> ::
#     def out = \"break";
#     def body = { <\"continue"> name1, name2 ::
#         def next = \"continue";
#         stat1; stat2
#     };
#     loopReduce(paraGeneratorFromValues(expr1, expr2))
#         { generator ::
#             def box = yieldBox();
#             <> ifValue { <> generator(box) }
#                 { nextGenerator ::
#                     body(boxGet(box)*);
#                     <> nextGenerator
#                 }
#                 { <\"break"> }
#         }
# }()
# ```
#
# with:
# * the break assignment omitted if there is no outer yield def.
# * the continue assignment omitted if there is no inner yield def
def parForExpression = {/
    @for
    breakDef = parOptBreakDef
    genClause = parGeneratorClause
    code = parNullaryClosure

    {
        def genInit = mapGet(genClause, "init");
        def genFormals = mapGet(genClause, "formals");

        def codePayload = tokenValue(code);
        def continueDef = ifValue { <> mapGet(codePayload, "yieldDef") }
            { name :: <> [makeVarDef(name, makeVarRef("continue"))] }
            { <> [] };

        def loopClosure = @[closure: [
            formals: genFormals,
            yieldDef: "continue",
            statements: [continueDef*, mapGet(codePayload, "statements")*]
        ]];

        def mainClosure = @[closure: [
            yieldDef: "break",
            statements: [
                breakDef*,
                makeVarDef("body", loopClosure),
                makeCallName("loopReduce", FOR_BODY_CLOSURE, genInit)
            ]
        ]];

        <> makeCall(mainClosure)
    }
/};

# Parses a general expression.
def implExpression = {/
    # This one's the top level "regular-looking" expression (in that it
    # covers the territory of C-style expressions).
    parLogicOrExpression
|
    # This one is only nominally "regular-looking" (in that not many C
    # family languages have function expressions).
    parFnExpression
|
    # These are "statement-like" expressions, in that they look like
    # corresponding statements in many (most?) C-derived languages.
    parDoExpression | parForExpression | parIfExpression |
    parSwitchExpression | parWhileExpression
/};
parExpression(implExpression);

# Parses a statement.
def implStatement = {/
    parVarDef | parFnDef | parExpression
/};
parStatement(implStatement);


#
# Exported functions
#

# Documented in Samizdat Layer 1 spec.
fn sam2Tree(program) {
    def tokens = ifIs { <> isString(program) }
        { <> sam2Tokenize(program) }
        { <> program };

    <> pegApply(parProgramOrError, tokens)
};

<> [
    sam2Tree: sam2Tree
]

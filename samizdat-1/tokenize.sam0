# Copyright 2013 the Samizdat Authors (Dan Bornstein et alia).
# Licensed AS IS and WITHOUT WARRANTY under the Apache License,
# Version 2.0. Details: <http://www.apache.org/licenses/LICENSE-2.0>

#
# Samizdat Layer 0 tokenizer
#


#
# Lookahead Reader
#
# A lookahead reader can read characters from a string, additionally
# allowing explicit backtracking.
#
# State consists of:
#
# * `@text` &mdash; The text being read.
# * `@size` &mdash; The size of the text in characters.
# * `@at` &mdash; The current cursor position.
#
# Convention: `do` prefix for public exposed functions, and `x` prefix for
# private non-dispatched functions.
#

# Gets the size.
xSize = { state :: mapletGet state @size };

# Gets the text.
xText = { state :: mapletGet state @text };

# Gets the cursor position.
xAt = { state :: mapletGet state @at };

# Gets the current cursor position.
doAt = { state :: <> @[@result=(xAt state)] };

# Returns whether the reader is at EOF.
doEof = { state :: <> @[@result=(lt (xAt state) (xSize state))] };

# Peeks at the next character without reading. Returns void at EOF.
doPeek = { state ::
    at = xAt state;
    <> ifValue { <> listletNth (xText state) at }
        { ch :: <> @[@result=ch] };
};

# Reads the next character. Returns void at EOF.
doRead = { state ::
    at = xAt state;
    <> ifValue { <> listletNth (xText state) at }
        { ch :: <> @[@result=ch @state=(mapletPut state @at (iadd at @1))] };
};

# Sets the cursor position to the given one.
doReset = { state at ::
    ifTrue { <> or { <> lt at @0 } { <> ge at (xSize state) } }
        { io0Die @"Reset out of range." };
    <> @[@state=(mapletPut state @at at)]
};

# Dispatch table.
READER_DISPATCH = @[
    @at    = doAt
    @eof   = doEof
    @peek  = doPeek
    @read  = doRead
    @reset = doReset
];

# Performs method dispatch.
readerDispatch = { state name rest* ::
    <> apply (mapletGet READER_DISPATCH name) state rest
};

# Returns a lookahead-enabled character reader.
makeReader = { programText ::
    <> object readerDispatch @[
        @at = @0
        @size = (lowSize programText)
        @text = programText
    ]
};


#
# Tokenizer function
#

# These are all the integer digits, as a maplet from stringlets to
# digit values.
INTEGER_CHARS = listletReduce @[=]
    @[@0 @1 @2 @3 @4 @5 @6 @7 @8 @9]
    { result n ::
        # Note: 48 == "0".
        <> mapletPut result (stringletFromIntlet (iadd @48 n)) n
    };

# Parses an integer.
parseInteger = { reader ::
    value = whileReduce @0 { result ::
        <> ifValue { <> reader @peek }
            { ch ::
                <> ifValue { <> mapletGet INTEGER_CHARS ch }
                    { n :: <> (iadd n (imul result @10)) }
            }
    };

    <> [:@integer value:];
};

# Skips over all characters until and including a newline.
skipUntilNewline = { reader ::
    while {
        <> ifValue { <> reader @read }
            { ch :: <> ne ch @"\n" }
            { <> false }
    }
};

# Parsers for particular whitespace characters.
WHITESPACE_DISPATCH = @[
    @" "  = { reader :: reader @read }
    @"\n" = { reader :: reader @read }
    @"#"  = skipUntilNewline
];

# Skips any whitespace at the current cursor.
skipWhitespace = { reader ::
    while {
        <> ifVoid { <> reader @peek }
            { <> false }
            { ch ::
                <> ifValue { <> mapletGet WHITESPACE_DISPATCH ch }
                    { parser :: parser reader; <> true }
                    { <> false }
            }
    }
};

# Single-character parser. Reads a single character, returning that
# value directly as a token.
oneCharParser = { reader :: <> [:(reader @read):] };

# Makes a one-or-two-character parser, given a two-character string.
# The result is a function which reads a character, and then peeks at
# the next one. It consumes the second character only if it matches as
# indicated.
makeOneTwoParser = { twoChars ::
    ch2 = stringletNth twoChars @1;
    result1 = [:(stringletNth twoChars @0):];
    result2 = [:twoChars:];

    parser = { reader ::
        reader @read; # Only ever called when the first character matched.
        <> ifValue { <> reader @peek }
            { ch ::
                <> ifTrue { <> eq ch ch2 }
                    { reader @read; <> result2 }
                    { <> result1 }
            }
    };

    <> parser;
};

# Mapping from token start character to the corresponding parser to use.
TOKEN_DISPATCH = mapletAdd
    (mapletMap INTEGER_CHARS { <> parseInteger })
    @[
        @"{" = oneCharParser
        @"}" = oneCharParser
        @"[" = oneCharParser
        @"]" = oneCharParser
        @"(" = oneCharParser
        @")" = oneCharParser
        @"=" = oneCharParser
        @"-" = oneCharParser
        @";" = oneCharParser
        @"*" = oneCharParser
        @":" = (makeOneTwoParser @"::")
        @"@" = (makeOneTwoParser @"@@")
        @"<" = (makeOneTwoParser @"<>")
    ];

# Reads a single token.
readToken = { reader ::
    skipWhitespace reader;
    <> ifValue { <> reader @peek }
        { ch ::
            <> ifValue { <> mapletGet TOKEN_DISPATCH ch }
                { parser :: <> parser reader }
                {
                    error = stringletCat @"No parser for character: "
                        (sourceStringlet ch);
                    skipUntilNewline reader; # Heuristic to help re-synch.
                    <> [:@error error:];
                }
        }
};

# Tokenizes the given string, using Samizdat Layer 0 token syntax.
# Returns a listlet of tokens.
tokenizex = { programText ::
    reader = makeReader programText;

    <> whileReduce @[] { result ::
        <> ifValue { <> readToken reader }
            { token :: <> listletAppend result token }
    }
};


########## OLD STUFF FOR REFERENCE ##########

# Tokenizes the given string, using Samizdat Layer 0 token syntax.
# Returns a listlet of tokens.
tokenize = { programText ::

    # These are all the valid identifier characters, as a set-like maplet.
    identifierChars = listletReduce @[=]
        @[@"0" @"1" @"2" @"3" @"4" @"5" @"6" @"7" @"8" @"9" @"_"
          @"a" @"b" @"c" @"d" @"e" @"f" @"g" @"h" @"i" @"j" @"k" @"l" @"m"
          @"n" @"o" @"p" @"q" @"r" @"s" @"t" @"u" @"v" @"w" @"x" @"y" @"z"
          @"A" @"B" @"C" @"D" @"E" @"F" @"G" @"H" @"I" @"J" @"K" @"L" @"M"
          @"N" @"O" @"P" @"Q" @"R" @"S" @"T" @"U" @"V" @"W" @"X" @"Y" @"Z"]
        { result ch :: <> mapletPut result ch null };

    # Parses an identifier.
    parseIdentifier = { at ::
        parseStep = { result at ::
            ch = get at;
            <> ifValue { <> mapletGet identifierChars ch }
                { <> parseStep (stringletCat result ch) (iadd at @1) }
                { <> @[@token=[:@identifier result:] @at=at] }
        };
        <> parseStep @"" at
    };

    # These are all the identifier parser mappings.
    identifierRules = mapletMap identifierChars { <> parseIdentifier };

    # Mapping from valid string escapes to their translated characters.
    stringEscapes = @[@"\\"=@"\\" @"\""=@"\"" @"n"=@"\n"];

    # Parses a string.
    parseString = { at ::
        parseStep = { result at ::
            ch = get at;
            nextAt = iadd at @1;
            <> ifTrue { <> eq ch @"\"" }
                { <> @[@token=[:@string result:] @at=nextAt] }
                {
                    <> ifTrue { <> ne ch @"\\" }
                        { <> parseStep (stringletCat result ch) nextAt }
                        {
                            ch2 = get nextAt;
                            <> ifValue { <> mapletGet stringEscapes ch2 }
                                { decoded ::
                                    <> parseStep
                                        (stringletCat result decoded)
                                        (iadd nextAt @1)
                                }
                        }
                }
        };
        <> parseStep @"" (iadd at @1) # +1 to skip the open quote.
    };

    # These are all the string parser mappings.
    stringRules = @[@"\"" = parseString]; # FIXME!

    # These are all the rules. Note: identifierRules has to be listed before
    # integerRules in order to avoid the former trampling on the latter.
    rules = mapletCat
        identifierRules
        stringRules;

    # Parses all the tokens.
    parseAll = { result at ::
        parsed = parseOne at;
        nextAt = mapletGet parsed @at;
        <> ifValue { <> mapletGet parsed @token }
            { token :: <> parseAll (listletAppend result token) nextAt }
            {
                <> ifValue { <> mapletGet parsed @error }
                    { error ::
                        io0Die (stringletCat
                            @"Tokenization failed at offset: "
                            (sourceStringlet nextAt) @"\n"
                            error @"\n")
                    }
                    { <> result }
            }
    };

    <> parseAll @[] @0
};

<> tokenize;
